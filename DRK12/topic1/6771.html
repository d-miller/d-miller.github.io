<!DOCTYPE HTML>
<html lang="en-gb" class="no-js">
    <head>
        <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=2.5,user-scalable=yes">
    <meta name="citation_publisher" content="Springer New York"/>
    <meta name="citation_title" content="The Future of Adaptive Learning: Does the Crowd Hold the Key?"/>
    <meta name="citation_doi" content="10.1007/s40593-016-0094-z"/>
    <meta name="citation_language" content="en"/>
    <meta name="citation_abstract_html_url" content="https://link.springer.com/article/10.1007/s40593-016-0094-z"/>
    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s40593-016-0094-z"/>
    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007%2Fs40593-016-0094-z.pdf"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s40593-016-0094-z&amp;api_key="/>
    <meta name="citation_firstpage" content="615"/>
    <meta name="citation_lastpage" content="644"/>
    <meta name="citation_author" content="Neil T. Heffernan"/>
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute"/>
    <meta name="citation_author" content="Korinn S. Ostrow"/>
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute"/>
    <meta name="citation_author_email" content="ksostrow@wpi.edu"/>
    <meta name="citation_author" content="Kim Kelly"/>
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute"/>
    <meta name="citation_author" content="Douglas Selent"/>
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute"/>
    <meta name="citation_author" content="Eric G. Van Inwegen"/>
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute"/>
    <meta name="citation_author" content="Xiaolu Xiong"/>
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute"/>
    <meta name="citation_author" content="Joseph Jay Williams"/>
    <meta name="citation_author_institution" content="Harvard University"/>
    <meta name="dc.identifier" content="10.1007/s40593-016-0094-z"/>
    <meta name="format-detection" content="telephone=no"/>
    <meta name="citation_fulltext_world_readable" content=""/>
    <meta name="description" content="Due to substantial scientific and practical progress, learning technologies can effectively adapt to the characteristics and needs of students. This article considers how learning technologies can..."/>
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:title" content="The Future of Adaptive Learning: Does the Crowd Hold the Key?"/>
    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/40593/26/2.jpg"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:site" content="SpringerLink"/>
    <meta name="twitter:description" content="Due to substantial scientific and practical progress, learning technologies can effectively adapt to the characteristics and needs of students. This article considers how learning technologies can..."/>
    <meta name="citation_journal_title" content="International Journal of Artificial Intelligence in Education"/>
    <meta name="citation_journal_abbrev" content="Int J Artif Intell Educ"/>
    <meta name="citation_volume" content="26"/>
    <meta name="citation_issue" content="2"/>
    <meta name="citation_issn" content="1560-4292"/>
    <meta name="citation_issn" content="1560-4306"/>
    <meta name="citation_online_date" content="2016/02/02"/>
    <meta name="citation_cover_date" content="2016/06/01"/>
    <meta name="citation_article_type" content="Article"/>
    <meta property="og:title" content="The Future of Adaptive Learning: Does the Crowd Hold the Key?"/>
    <meta property="og:type" content="Article"/>
    <meta property="og:url" content="https://link.springer.com/article/10.1007/s40593-016-0094-z"/>
    <meta property="og:image" content="https://static-content.springer.com/cover/journal/40593/26/2.jpg"/>
    <meta property="og:site_name" content="SpringerLink"/>
    <meta property="og:description" content="Due to substantial scientific and practical progress, learning technologies can effectively adapt to the characteristics and needs of students. This article considers how learning technologies can..."/>

        <title>The Future of Adaptive Learning: Does the Crowd Hold the Key? | SpringerLink</title>
        <link rel="canonical" href="https://link.springer.com/article/10.1007/s40593-016-0094-z"/>
        <link rel="shortcut icon" href="/springerlink-static/2055516157/images/favicon/favicon.ico">
<link rel="icon" sizes="16x16 32x32 48x48" href="/springerlink-static/2055516157/images/favicon/favicon.ico">
<link rel="icon" sizes="16x16" type="image/png" href="/springerlink-static/2055516157/images/favicon/favicon-16x16.png">
<link rel="icon" sizes="32x32" type="image/png" href="/springerlink-static/2055516157/images/favicon/favicon-32x32.png">
<link rel="icon" sizes="48x48" type="image/png" href="/springerlink-static/2055516157/images/favicon/favicon-48x48.png">
<link rel="apple-touch-icon" href="/springerlink-static/2055516157/images/favicon/app-icon-iphone@3x.png">
<link rel="apple-touch-icon" sizes="72x72" href="/springerlink-static/2055516157/images/favicon/ic_launcher_hdpi.png">
<link rel="apple-touch-icon" sizes="76x76" href="/springerlink-static/2055516157/images/favicon/app-icon-ipad.png">
<link rel="apple-touch-icon" sizes="114x114" href="/springerlink-static/2055516157/images/favicon/app-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/springerlink-static/2055516157/images/favicon/app-icon-iphone@2x.png">
<link rel="apple-touch-icon" sizes="144x144" href="/springerlink-static/2055516157/images/favicon/ic_launcher_xxhdpi.png">
<link rel="apple-touch-icon" sizes="152x152" href="/springerlink-static/2055516157/images/favicon/app-icon-ipad@2x.png">
<link rel="apple-touch-icon" sizes="180x180" href="/springerlink-static/2055516157/images/favicon/app-icon-iphone@3x.png">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/springerlink-static/2055516157/images/favicon/ic_launcher_xxhdpi.png">
        <link rel="dns-prefetch" href="//fonts.gstatic.com">
<link rel="dns-prefetch" href="//fonts.googleapis.com">
<link rel="dns-prefetch" href="//google-analytics.com">
<link rel="dns-prefetch" href="//www.google-analytics.com">
<link rel="dns-prefetch" href="//www.googletagservices.com">
<link rel="dns-prefetch" href="//www.googletagmanager.com">
<link rel="dns-prefetch" href="//static-content.springer.com">
        <link rel="stylesheet" href="/springerlink-static/2055516157/css/basic.css" media="screen">
<link rel="stylesheet" href="/springerlink-static/2055516157/css/styles.css" class="js-ctm" media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
<link rel="stylesheet" href="/springerlink-static/2055516157/css/print.css" media="print">


            <script type="text/javascript">
        window.Krux||((Krux=function(){Krux.q.push(arguments);}).q=[]);
        var dataLayer = [{
                'GA Key':"UA-26408784-1",
                'Features':["leaderboardadverts","eventtracker"],
                'Event Category':"Article",
                'Open Access':"N",
                'Labs':"Y",
                'DOI':"10.1007/s40593-016-0094-z",
                'VG Wort Identifier':"vgzm.415900-10.1007-s40593-016-0094-z",
                'hasAccess':"Y",
                'Full HTML':"Y",
                'Has Body':"Y",
                'Static Hash':"2055516157",
                'Has Preview':"N",
                'user':{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},
                'content':{"serial":{"eissn":"1560-4306","pissn":"1560-4292"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Artificial Intelligence (incl. Robotics)","2":"Educational Technology","3":"User Interfaces and Human Computer Interaction","4":"Computers and Education"},"secondarySubjectCodes":{"1":"I21017","2":"O21000","3":"I18067","4":"I24032"}},"sucode":"Computer Science"}},
                'Access Type':"subscription",
                'Page':"article",
                'Bpids':"",
                'Bpnames':"",
                'SubjectCodes':"SCI, SCI21017, SCO21000, SCI18067, SCI24032",
                'session':{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},
                'eventTrackerBaseUrl':"https://event-tracker.springernature.com",
                'Keywords':"Crowdsourcing, Learnersourcing, Feedback, Learning gains, Online learning platform, Adaptive learning technologies, ASSISTments",
                'Country':"US",
                'Journal Id':"40593",
                'Journal Title':"International Journal of Artificial Intelligence in Education",

                    'doi': "10.1007-s40593-016-0094-z",
                    'kwrd': ["Crowdsourcing","Learnersourcing","Feedback","Learning_gains","Online_learning_platform","Adaptive_learning_technologies","ASSISTments"],
                    'pmc': ["I","I21017","O21000","I18067","I24032"],
                    'BPID': ["1"],
                    'ksg': Krux.segments,
                    'kuid': Krux.uid,

        }];
    </script>

<script type="text/javascript" src="/springerlink-static/2055516157/js/jquery-3.3.1.min.js"></script>

        <script type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>

<script type="text/javascript">
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>

    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-WCF9Z9');</script>

    </head>
    <body>
        <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
                      height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <div class="skip-to">
    <a class="skip-to__link pseudo-focus" href="#main-content">Skip to main content</a>
        <a class="skip-to__link skip-to__link--contents pseudo-focus" href="#article-contents">Skip to sections</a>
</div>
        <div class="page-wrapper">
            <noscript>
    <div class="nojs-banner u-interface">
        <p>This service is more advanced with JavaScript available, learn more at <a
                href="http://activatejavascript.org" target="_blank" rel="noopener">http://activatejavascript.org</a>
        </p>
    </div>
</noscript>
                    <div id="leaderboard" class="leaderboard u-hide" data-component="SpringerLink.GoogleAds" data-namespace="leaderboard">
            <div class="leaderboard__wrapper">
                <p class="leaderboard__label">Advertisement</p>
                <button class="leaderboard__hide" title="Hide this advertisement"  data-track="click" data-track-action="Hide advertisement" data-track-label="">Hide</button>
                <div id="doubleclick-leaderboard-ad" class="leaderboard__ad u-pt-24"></div>
            </div>
        </div>

                <header id="header" class="header u-interface">
        <div class="header__content">
            <div class="header__menu-container">
                    <a id="logo" class="site-logo" href="/" title="Go to homepage">
                <div class="u-screenreader-only">SpringerLink</div>
    <svg class="site-logo__springer" width="148" height="30" role="img" focusable="false" aria-hidden="true">
        <image width="148" height="30" alt="" src="/springerlink-static/2055516157/images/png/springerlink.png" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="/springerlink-static/2055516157/images/svg/springerlink.svg"></image>
    </svg>

    </a>


                    <nav id="search-container" class="u-inline-block">
                        <div class="search">
                            <div class="search__content">
                                <form class="u-form-single-input" action="/search" method="get" role="search">
    <label for="search-springerlink">Search SpringerLink</label>
    <div class="u-relative">
        <input id="search-springerlink" name="query" type="text" autocomplete="off" value="">
        <input class="u-hide-text" type="submit" value="Submit" title="Submit">
        <svg class="u-vertical-align-absolute" width="13" height="13" viewBox="222 151 13 13" version="1.1" xmlns="http://www.w3.org/2000/svg" focusable="false" aria-hidden="true" role="presentation">
            <path d="M227 159C228.7 159 230 157.7 230 156 230 154.3 228.7 153 227 153 225.3 153 224 154.3 224 156 224 157.7 225.3 159 227 159L227 159 227 159 227 159ZM230 160.1L231.1 159 233.9 161.7C234.2 162.1 234.2 162.6 233.9 162.9 233.6 163.2 233.1 163.2 232.7 162.9L230 160.1 230 160.1 230 160.1 230 160.1ZM227 161L227 161C224.2 161 222 158.8 222 156 222 153.2 224.2 151 227 151 229.8 151 232 153.2 232 156 232 158.8 229.8 161 227 161L227 161 227 161 227 161 227 161Z" stroke="none" fill-rule="evenodd"/>
        </svg>
    </div>
</form>
                            </div>
                        </div>
                    </nav>

                    <nav class="nav-container u-interface">
    <div class="global-nav__wrapper">
        <div class="search-button">
            <a class="search-button__label" href="#search-container">
                <span class="search-button__title">Search</span><svg width="12" height="12" viewBox="222 151 12 12" version="1.1" xmlns="http://www.w3.org/2000/svg" focusable="false" aria-hidden="true" role="presentation">
                    <path d="M227 159C228.7 159 230 157.7 230 156 230 154.3 228.7 153 227 153 225.3 153 224 154.3 224 156 224 157.7 225.3 159 227 159L227 159 227 159 227 159ZM230 160.1L231.1 159 233.9 161.7C234.2 162.1 234.2 162.6 233.9 162.9 233.6 163.2 233.1 163.2 232.7 162.9L230 160.1 230 160.1 230 160.1 230 160.1ZM227 161L227 161C224.2 161 222 158.8 222 156 222 153.2 224.2 151 227 151 229.8 151 232 153.2 232 156 232 158.8 229.8 161 227 161L227 161 227 161 227 161 227 161Z" stroke="none" fill-rule="evenodd"></path>
                </svg>
            </a>
        </div>

        <ul class="global-nav" data-component="SV.Menu" data-title="Navigation menu" data-text="Menu">
            <li>
                <a href="/">
                    <span class="u-overflow-ellipsis">Home</span>
                </a>
            </li>

                <li class="global-nav__logged-out">
                    <a class="test-login-link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs40593-016-0094-z">
                        <span class="u-overflow-ellipsis">Log in</span>
                    </a>
                </li>

        </ul>
    </div> 
</nav> 
            </div>

        </div>
    </header>

            
            <main id="main-content" class="main-wrapper" tabindex="-1">
                <div class="main-container uptodate-recommendations-off">
                    <aside class="main-sidebar-left">
                        <div class="main-sidebar-left__content">
                            <div class="cover-image test-cover" itemscope>
                                    <a class="test-cover-link" href="/journal/40593">
        <span class="u-screenreader-only">International Journal of Artificial Intelligence in Education</span>
        <img class="test-cover-image" src="https://media.springernature.com/w306/springer-static/cover/journal/40593/26/2.jpg" itemprop="image" alt=""/>
    </a>


                            </div>
                        </div>
                    </aside>
                    <div class="main-body" data-role="NavigationContainer">
                                <div class="cta-button-container cta-button-container--top cta-button-container--stacked u-mb-16 u-hide-two-col">
                    <div>
            <a href="/content/pdf/10.1007%2Fs40593-016-0094-z.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right" title="Download this article in PDF format" rel="noopener" data-track="click" data-track-action="Pdf download" data-track-label="">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"/></g></g></g></svg>
                <span class="hide-text-small">Download</span>
                <span>PDF</span>
            </a>
        </div>

        </div>



                        <article class="main-body__content">
                            <div xmlns="http://www.w3.org/1999/xhtml" class="FulltextWrapper"><div class="ArticleHeader main-context"><div id="enumeration" class="enumeration"><p><a href="/journal/40593" title="International Journal of Artificial Intelligence in Education" data-track="click" data-track-action="Journal title" data-track-label=""><span class="JournalTitle">International Journal of Artificial Intelligence in Education</span></a></p><p class="icon--meta-keyline"><span class="ArticleCitation_Year"><time datetime="2016-06">June 2016</time>, </span><span class="ArticleCitation_Volume">Volume 26, </span><a class="ArticleCitation_Issue" href="/journal/40593/26/2/page/1" data-track="click" data-track-action="Article issue" data-track-label="">Issue 2</a>,
                       <span class="ArticleCitation_Pages"> pp 615–644</span><span class="u-inline-block u-ml-4"> | <a href="#citeas" data-track="click" data-track-action="Cite as link" data-track-label="Enumeration section">Cite as</a></span></p></div><div class="MainTitleSection"><h1 class="ArticleTitle" lang="en">The Future of Adaptive Learning: Does the Crowd Hold the Key?</h1></div><div class="authors u-clearfix" data-component="SpringerLink.Authors"><ul class="u-interface u-inline-list authors__title" data-role="AuthorsNavigation"><li><span>Authors</span></li><li><a href="#authorsandaffiliations" data-track="click" data-track-action="Authors and affiliations tab" data-track-label="">Authors and affiliations</a></li></ul><div class="authors__list" data-role="AuthorsList"><ul class="test-contributor-names"><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Neil T. Heffernan</span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Korinn S. Ostrow</span><span class="author-information"><span class="authors__contact"><a href="mailto:ksostrow@wpi.edu" title="ksostrow@wpi.edu" itemprop="email" data-track="click" data-track-action="Email author" data-track-label=""><img src="/springerlink-static/images/svg/email.svg" height="24" width="24" alt="Email author" /></a></span></span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Kim Kelly</span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Douglas Selent</span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Eric G. Van Inwegen</span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Xiaolu Xiong</span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Joseph Jay Williams</span></li></ul></div></div><div class="main-context__container" data-component="SpringerLink.ArticleMetrics"><div class="main-context__column"><span><span class="test-render-category">Article</span></span><div class="article-dates"><span class="article-dates__label">First Online: </span><span class="article-dates__first-online"><time datetime="2016-02-02">02 February 2016</time></span></div></div><div class="main-context__column">    <ul id="book-metrics" class="article-metrics u-sansSerif">
            <li class="article-metrics__item">
                     <span class="article-metrics__views">2.5k</span>
                     <span class="article-metrics__label">Downloads</span>
            </li>
            <li class="article-metrics__item">
                    <a class="article-metrics__link gtm-citations-count" href="https://citations.springer.com/item?doi&#x3D;10.1007/s40593-016-0094-z" target="_blank" rel="noopener"
                       title="Visit Springer Citations for full citation details" id="citations-link">
                            <span id="citations-count-number" class="test-metric-count c-button-circle gtm-citations-count">2</span>
                       <span class="test-metric-name article-metrics__label gtm-citations-count">Citations</span>
                    </a>
            </li>
    </ul>
</div></div></div><section class="Abstract" id="Abs1" tabindex="-1" lang="en"><h2 class="Heading">Abstract</h2><p id="Par1" class="Para">Due to substantial scientific and practical progress, learning technologies can effectively adapt to the characteristics and needs of students. This article considers how learning technologies can adapt over time by crowdsourcing contributions from teachers and students – explanations, feedback, and other pedagogical interactions. Considering the context of ASSISTments, an online learning platform, we explain how interactive mathematics exercises can provide the workflow necessary for eliciting feedback contributions and evaluating those contributions, by simply tapping into the everyday system usage of teachers and students. We discuss a series of randomized controlled experiments that are currently running within ASSISTments, with the goal of establishing proof of concept that students and teachers can serve as valuable resources for the perpetual improvement of adaptive learning technologies. We also consider how teachers and students can be motivated to provide such contributions, and discuss the plans surrounding PeerASSIST, an infrastructure that will help ASSISTments to harness the power of the crowd. Algorithms from machine learning (i.e., multi-armed bandits) will ideally provide a mechanism for managerial control, allowing for the automatic evaluation of contributions and the personalized provision of the highest quality content. In many ways, the next 25 years of adaptive learning technologies will be driven by the crowd, and this article serves as the road map that ASSISTments has chosen to follow.</p></section><div class="KeywordGroup" lang="en"><h2 class="Heading">Keywords</h2><span class="Keyword">Crowdsourcing </span><span class="Keyword">Learnersourcing </span><span class="Keyword">Feedback </span><span class="Keyword">Learning gains </span><span class="Keyword">Online learning platform </span><span class="Keyword">Adaptive learning technologies </span><span class="Keyword">ASSISTments </span></div><div class="article-actions--inline" id="article-actions--inline" data-component="article-actions--inline"></div><div id="body"><section id="Sec1" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading">Evolving Adaptive Learning Technologies Through Crowdsourced Contributions</h2><div class="content"><p id="Par2" class="Para">For this Special Issue, we were asked to predict elements that would drive the next 25 years of AIED research. Clairvoyance is difficult, if not impossible, and if we were to provide readers with definitive strategies to guide the next quarter century of research, we would likely suggest far more “misses” than “hits.” Instead, we use this work to examine the modest steps that ASSISTments, a popular online learning platform, will be taking to accommodate issues of growing importance. Over the next 25 years, it is our hope that adaptive learning technologies will extend support for best practices in K-12 learning through rigorous experimentation to identify and implement personalized educational interventions in authentic learning environments. We anticipate that while big data will be used to improve these platforms (i.e., through educational data mining and learning analytics), innovations in this area will be restricted by pedagogy and by fine-grained, personalized support for all learners. Still, growth rooted in best practices will be necessary to keep the field from growing stagnant.</p><p id="Par3" class="Para">Specifically, this article considers how improvements for a perpetually evolving educational ecosystem can be solicited dynamically and at scale through <em class="EmphasisTypeItalic ">crowdsourcing</em> (Kittur et al. <span class="CitationRef"><a href="#CR19">2013</a></span>; Howe <span class="CitationRef"><a href="#CR14">2006</a></span>). We provide a brief background on crowdsourcing, noting the issues inherent to the concept, and the novelty of its use in educational domains. We follow this discussion with a detailed description of the ASSISTments platform and its feedback capabilities in their current form. We then highlight a number of randomized controlled experiments that have run or are currently running within ASSISTments that outline the steps that the ASSISTments team is taking to implement crowdsourcing within the platform. We believe that others in the AIED community should consider similar work in the coming years. We then outline the process by which ASSISTments plans to implement crowdsourcing, through an infrastructure we refer to as PeerASSIST. We explain how crowdsourced feedback contributions will be collected and how the platform will use sequential design as a managerial control to isolate and deliver high quality contributions to other learners. We conclude our discussion by linking our work within ASSISTments to general implications for the AIED community and the coming 25 years of research.</p><p id="Par4" class="Para">Recent research has suggested that large improvements to adaptive learning technologies can be produced through a multitude of small-scale, organic contributions from distributed populations of teachers and students. Users of these platforms receive content via online and blended education systems and, in return, provide data on learning and interactions (i.e., log files). It would be relatively simple to incorporate more elaborate user contributions, in the form of solution explanations or ‘work shown,’ as pedagogical innovations that underlie systemic change (Howe <span class="CitationRef"><a href="#CR14">2006</a></span>; Von Ahn <span class="CitationRef"><a href="#CR41">2009</a></span>). Thus, when considering the next 25 years of AIED, especially at scale, safety will be in numbers, and ASSISTments will be following the crowd.</p></div></section><section id="Sec2" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading">Crowdsourcing</h2><div class="content"><p id="Par5" class="Para">Extensive discussion surrounds the challenge of clearly defining crowdsourcing (Estellés-Arolas and González-Ladrón-de-Guevara <span class="CitationRef"><a href="#CR8">2012</a></span>). In this article we use the term crowdsourcing to contrast obtaining curriculum or pieces of content designed by a single expert (or a small team of experts) (Porcello and Hsi <span class="CitationRef"><a href="#CR30">2013</a></span>) with obtaining contributions from many people, who tend not to be restrictively vetted or selected, and whose efforts are voluntary. There is tremendous evidence for the power of crowdsourcing in human-computer interaction research (Doan et al. <span class="CitationRef"><a href="#CR7">2011</a></span>; Howe <span class="CitationRef"><a href="#CR14">2006</a></span>; Kittur et al. <span class="CitationRef"><a href="#CR19">2013</a></span>), with recent work covered by many publications at venues like HCOMP (Conference on Human Computation and Crowdsourcing), CSCW (Computer Supported Cooperative Work and Social Computing), CHI (Computer-Human Interaction), and Collective Intelligence (see also Malone and Bernstein <span class="CitationRef"><a href="#CR23">2015</a></span>). Despite the trending popularity of crowdsourcing, adaptive learning settings have not taken advantage of the approach as a viable framework for success.</p><p id="Par6" class="Para">Not to be confused with the “wisdom of crowds,” or the assumption that the whole is greater than the sum of its parts (Surowiecki <span class="CitationRef"><a href="#CR36">2004</a></span>), crowdsourcing does not necessarily require a “wise” crowd, or one with cognitive diversity, independence, decentralization, and aggregation, as described by the framework set forth by Surowiecki (<span class="CitationRef"><a href="#CR36">2004</a></span>). Many instances of crowdsourcing have proven successful without crowd member independence or the aggregation of opinions (Saxton et al. <span class="CitationRef"><a href="#CR33">2013</a></span>). It therefore follows that any crowd, even those comprised of novices rather than domain experts, may serve as a helpful resource. By sourcing content contributions from users within adaptive learning platforms, it is possible to expand the breadth and diversity of available material beyond that born of just a few designers, supporting the personalization of online educational content (Organisciak et al. <span class="CitationRef"><a href="#CR28">2014</a></span>; Weld et al. <span class="CitationRef"><a href="#CR44">2012</a></span>). Rather than designing a theoretical framework for the sound implementation of crowdsourcing across platforms or in differing scenarios (see Saxton et al. (<span class="CitationRef"><a href="#CR33">2013</a></span>) for a meta-analysis exemplifying structured crowdsourcing models), we focus primarily on the logistics of, and issues surrounding, outsourcing content creation to active users of an adaptive learning platform.</p><p id="Par7" class="Para">In addition to the academic literature in human-computer interaction, many well-known websites and Web 2.0 services (i.e., Facebook, Flicker) involve crowdsourcing activities. Perhaps the most prominent success story built on the crowdsourcing approach is Wikipedia, the free online encyclopedia that relies on crowdsourcing to author and edit content. Wikipedia has surpassed the capabilities of previous electronic encyclopedias (i.e., Encyclopedia Britannica) by taking an approach that was initially criticized and met with skepticism: a wide range of users, all free to create, edit, flag, and delete content. This approach, now common to all “wikis,” constitutes a <em class="EmphasisTypeItalic ">knowledge base building model</em> (Saxton et al. <span class="CitationRef"><a href="#CR33">2013</a></span>), requiring high levels of crowd collaboration with little-to-no compensation in return.</p><p id="Par8" class="Para">In contrast, Stack Overflow and Yahoo Answers are two examples of crowdsourcing sites designed to allow users to interact and to provide others with assistance, thereby building a knowledge base. Such sites have shown compelling benefits (Anderson et al. <span class="CitationRef"><a href="#CR2">2012</a></span>). For instance, Stack Overflow is among the top 50 most visited websites on the Internet and is used by 26 million programmers each month (<span class="ExternalRef"><a target="_blank" rel="noopener" href="http://stackexchange.com/about"><span class="RefSource">http://stackexchange.com/about</span></a></span>). Within this implementation of crowdsourcing, any user is able to ask questions related to programming, and others in the community are able to provide answers. Additionally, users can “upvote” or “downvote” questions and answers to promote the most accurate and helpful content. Further, questions can be linked, marked as duplicates, flagged as inappropriate, or commented upon with general responses. Stack Overflow then uses an algorithm to rank users according to the “value” of his or her answers, thereby helping to efficiently highlight quality content from domain experts in the crowd.</p><p id="Par9" class="Para">In many other large technological platforms, processes for crowdsourcing have provided valuable solutions. Popular examples can be categorized by various model types within the theoretical framework set forth by Saxton et al. (<span class="CitationRef"><a href="#CR33">2013</a></span>), including those focused on <em class="EmphasisTypeItalic ">collaborative software development</em> like game design (Von Ahn and Dabbish <span class="CitationRef"><a href="#CR40">2008</a></span>) and the programming of mobile apps by sourcing the efforts of experts with specialized skills (Retelny et al. <span class="CitationRef"><a href="#CR31">2014</a></span>), those focused on <em class="EmphasisTypeItalic ">citizen media production</em> (i.e., YouTube, Reddit), and those focused on <em class="EmphasisTypeItalic ">collaborative science projects</em> like the digitization and translation of books and addresses, and image identification at scale (Griswold <span class="CitationRef"><a href="#CR11">2014</a></span>). Such crowdsourcing activities also interface with discussions around “Big Data” and “Data Science” (Manyika et al. <span class="CitationRef"><a href="#CR24">2011</a></span>; Boyd and Crawford <span class="CitationRef"><a href="#CR6">2012</a></span>) as novel kinds of data and analyses emerge as social network interactions (Tan et al. <span class="CitationRef"><a href="#CR37">2013</a></span>) and crowdsourcing behaviors (Franklin et al. <span class="CitationRef"><a href="#CR10">2011</a></span>) grow in popularity.</p><p id="Par10" class="Para">While the previous examples offer powerful and compelling uses of crowdsourcing, the concept still faces challenges in the realm of education. Issues that arise within educational domains, including managerial control, or how to evaluate and enforce high quality user contributions, continue to plague crowdsourcing systems in other domains (Saxton et al. <span class="CitationRef"><a href="#CR33">2013</a></span>). For instance, Stack Overflow cannot outwardly measure which answers have more of an effect on learning outcomes. Although users might assume that highly “upvoted” content is the most reliable, there is no qualitative way to survey users after having read each answer to determine differences in learning gains. Similarly, open authorship on “wikis” allows users to supply inaccurate content or to destroy accurate content through malicious edits. Without a principled approach for evaluating the quality of contributions beyond user opinion, Wikipedia faces skepticism from those in education about the reliability and the veracity of its content.</p><section id="Sec3" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Improving Education Through “Teachersourcing”</h3><p id="Par11" class="Para">Despite the lack of its use within educational domains, crowdsourcing holds great promise for the future of adaptive education, with few substantial obstacles (Williams et al. <span class="CitationRef"><a href="#CR47">2015a</a></span>). Teachers and experts can curate and collect high quality educational resources online (Porcello and Hsi <span class="CitationRef"><a href="#CR30">2013</a></span>), with research showing success in authoring expert knowledge for intelligent tutors and educational resources by using crowds of teachers (Floryan and Woolf <span class="CitationRef"><a href="#CR9">2013</a></span>; Aleahmad et al. <span class="CitationRef"><a href="#CR1">2008</a></span>). However, the majority of adaptive learning technologies that offer personalized instruction lack the infrastructure required to obtain sufficient contributions from the crowd and to then return customized instruction to match students’ needs. For example, to solve a problem requiring students to add fractions with unlike denominators, adaptive learning systems typically provide scaffolded instruction that walks the student through finding a common denominator, creating equivalent fractions, and then adding the fractions. However, the Common Core State Standards (NGACBP and CCSSO <span class="CitationRef"><a href="#CR27">2010</a></span>) emphasize multiple approaches to problem solving, often with varying complexity. For example, one student may use a manipulative, such as fractions of a circle, to find equivalent fractions and then carry out the addition. Another student may take a more sophisticated approach by listing all equivalent fractions for each fraction in order to find a common denominator. A third student may instead use an algorithm to find the least common multiple and carry through with the addition using this as the denominator. An adaptive learning system that is assisting a student with this problem should know all potential approaches, know which approach is most appropriate given the student’s actions, and provide the assistance that will optimize benefit for each student. This is where the idea of implementing crowdsourced content or feedback within an educational context can grow exceedingly necessary. A single teacher may not be the most apt at explaining all topics to all students. If multiple approaches exist to solve a problem, and the teacher consistently teaches only a single approach or method, students may fail to grasp what they would perhaps otherwise understand when taught using a different approach (Ma <span class="CitationRef"><a href="#CR22">1999</a></span>).</p><p id="Par12" class="Para">Crowdsourcing feedback material from teachers would allow for an expanse in the probability that students will learn from an effective teacher, or possibly from an effective combination of teachers (Weld et al. <span class="CitationRef"><a href="#CR44">2012</a></span>). Some platforms in the AIED community are already beginning to consider crowdsourcing, and a number of researchers in the community have shown interest in the topic. An academic collaboration has paired Professor Kong at Worcester Polytechnic Institute with Yahoo Answers to make progress in better predicting the quality of questions, the helpfulness of answers, and the expertise of users (Zhang et al. <span class="CitationRef"><a href="#CR49">2014</a></span>). However, few adaptive learning technologies have considered this approach, and perhaps even fewer have considered crowdsourcing content from learners.</p></section><section id="Sec4" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">An Alternative Approach: “Learnersourcing”</h3><p id="Par13" class="Para">Crowdsourcing feedback does not necessarily have to stop at teachers, or those considered domain experts. We believe that students can provide high quality worked examples of their solution path for a problem, or essentially “show their work.” Not only might the process of explaining their actions help to solidify their understanding of the content, but the feedback they provide can in turn be connected to the problem for the benefit of future students (Kulkarni et al. <span class="CitationRef"><a href="#CR20">2015</a></span>). Student users spanning classrooms around the world offer a wealth of information; they can provide versatile explanations that would allow the system to incorporate all potential approaches for solving a particular problem. Currently in most adaptive learning systems, when a student requests feedback in the form of a hint or scaffold, only a single approach is provided. Crowdsourcing student explanations has the potential to expand the capability of these systems to provide multiple, vetted approaches to the right students at the right times.</p><p id="Par14" class="Para">Engaging in “learnersourcing” (a term coined by Juho Kim and the CSAIL team at MIT, see Kim (<span class="CitationRef"><a href="#CR16">2015</a></span>)) may also be beneficial to students, if pedagogically useful activities like prompts for self-explanation are used to elicit student contributions (Williams and Lombrozo <span class="CitationRef"><a href="#CR46">2010</a></span>). One line of work has had learners organically generate outlines for videos, by prompting them to answer questions like “What was the section you just watched about?”, having those answers vetted by other learners, and using the resulting information to dynamically build an interactive outline that can be delivered alongside the video (Weir et al. <span class="CitationRef"><a href="#CR43">2015</a></span>). Weir et al. (<span class="CitationRef"><a href="#CR43">2015</a></span>) showed that this type of learnersourcing workflow could produce outlines for videos that lay out subgoals for learning in a way that is indistinguishable from outlines painstakingly produced by experts. We use the term “learnersourcing” in the present work simply to signify the crowd as comprised of student users of an online learning platform.</p><p id="Par15" class="Para">In theory, crowdsourcing could play an integral role in the future of adaptive learning. However, the issues surrounding the actual practice of crowdsourcing feedback within adaptive learning technologies are complex. What type of a system must exist for crowdsourcing to be easy and natural for users? After collecting a variety of feedback approaches for a particular problem, how should the system go about dispensing the proper feedback to the proper students at the proper times? We consider these issues, as well as others, as we discuss the intended future of harnessing the crowd within ASSISTments.</p></section><section id="Sec5" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Issues Inherent to Learnersourcing</h3><p id="Par16" class="Para">Although crowdsourcing has offered solutions for tasks that range from menial to complex, and while the technique will surely continue to prove effective moving into the future, one may argue that the use of crowdsourcing (especially learnersourcing) within adaptive learning technologies may carry a number of risks. Through a meta-analysis of 103 websites that implement some form of crowdsourcing, Saxton et al. (<span class="CitationRef"><a href="#CR33">2013</a></span>) established a comprehensive taxonomy for guiding the framework of crowdsourced designs. The approach to crowdsourcing that will guide the future of research within ASSISTments falls into their <em class="EmphasisTypeItalic ">knowledge base building model</em> framework. Considering the author’s’ summary of this type of model, “information- or knowledge-generation processes are outsourced to community users, and diverse types of incentive measures and quality control mechanisms are utilized to elicit quality knowledge and information that may be latent in the virtual crowd’s ‘brain’” (Saxton et al. <span class="CitationRef"><a href="#CR33">2013</a></span>). Essentially, feedback creation could be outsourced to student users and can be incentivized through a grading rationale, with content quality managed by algorithms that promote the subsequent presentation of explanations that produce the greatest learning.</p><p id="Par17" class="Para">Saxton et al. (<span class="CitationRef"><a href="#CR33">2013</a></span>) suggest three primary issues with regard to crowdsourcing: 1) the “what” being outsourced, 2) the collaboration required from the crowd, and 3) managerial control over the quality of crowd based contributions. When outsourcing content creation to teachers, we are retrieving data from (more or less) domain experts. However, when branching to learnersourcing, we are accepting contributions from “experts-in-training.” We argue that learnersourcing is acceptable within adaptive learning technologies if approached properly; we have lowered the complexity of the task at hand by relabeling feedback creation as “self-explanation.” The complexity of providing self-explanations for solutions to problem content may vary drastically in relation to the content in question. For instance, in mathematics, asking a student to explain how he or she solved a perimeter problem may be far less complex than asking a student to explain how he or she solved a logarithmic function. As these solutions are being sourced from the learner, or an “expert-in-training,” it grows more difficult to collect accurate and high quality content. Crowd collaboration can serve to alleviate some of this risk while establishing a framework for managerial control. Devising a voting methodology for the strongest content would allow for crowd collaboration, but may lead to social strife in classrooms if feedback is not collected anonymously (i.e., the potential for “downvotes” to high quality content as a form of bullying or social dominance). As Saxton et al. (<span class="CitationRef"><a href="#CR33">2013</a></span>) note, not all crowdsourcing systems require collaboration as part of a successful model, and as such, we consider it possible to establish learnersourcing that does not necessarily rely on the crowd’s collaborative impact. Content control within learnersourcing is easily the most difficult issue to tackle, and managerial control has been considered one of the greater challenges of crowdsourcing in general (Howe <span class="CitationRef"><a href="#CR14">2006</a></span>; Howe <span class="CitationRef"><a href="#CR15">2008</a></span>; McAfee <span class="CitationRef"><a href="#CR25">2006</a></span>).</p><p id="Par18" class="Para">In the present work, we discuss a single method for implementing crowdsourcing within an online learning platform. We do not suggest that ASSISTments is the only platform capable of learnersourcing, nor do we suggest that we have found the ideal framework for implementation in other adaptive learning technologies. The framework that we set forth may or may not be generalizable to other platforms. However, we outline the steps that our team will be taking in the coming years (note that a large portion of this work is not yet substantiated) in hopes that the AIED community will consider crowdsourcing and the related issues as driving forces for research on the effects of feedback within adaptive learning technologies over the next quarter century.</p></section></div></section><section id="Sec6" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading">Implementing Crowdsourcing Within Assistments</h2><div class="content"><p id="Par19" class="Para">In the remainder of this article, we discuss how we hope to extend the ASSISTments platform to enable large-scale improvements through crowdsourcing from teachers and students. ASSISTments is an online learning platform offered as a free service of Worcester Polytechnic Institute. The platform serves as a powerful tool providing students with <em class="EmphasisTypeItalic ">assistance</em> while offering teachers <em class="EmphasisTypeItalic ">assessment</em>. Doubling its user population each year for almost a decade, ASSISTments is currently used by hundreds of teachers and over 50,000 students around the world with over 10 million problems solved last year. At its core, the premise of ASSISTments is simple: allow computers to do what computers do best while freeing up teachers to do what teachers do best. In ASSISTments, teachers can author questions to assign to their students, or select content from open libraries of pre-built material. While the majority of these libraries provide certified mathematics content, the system is constantly growing with regard to other domains (i.e., chemistry, electronics), and teachers and researchers are able to author content in any domain.</p><p id="Par20" class="Para">Specifically, the ASSISTments platform is driving the future of adaptive learning in some unique ways. The first is the platform’s ability to conduct sound educational research at scale efficiently, ethically, and at a low cost. ASSISTments specializes in helping researchers run practical, minimally invasive randomized controlled experiments using student level randomization. As such, the platform has allowed for the publication of over 18 peer-reviewed articles on learning since its inception in 2002 <strong class="EmphasisTypeBold ">(</strong>Heffernan and Heffernan <span class="CitationRef"><a href="#CR13">2014</a></span> <strong class="EmphasisTypeBold ">)</strong>. While other systems provide many of the same classroom benefits as ASSISTments, few merit an infrastructure that also allows educational researchers to design and implement content-based experiments without an extensive knowledge of computer programming or other specialized skills with an equally steep learning curve. Recent NSF funding has allowed for researchers around the country to design and implement studies within the system, moving the platform towards acceptance as a shared scientific instrument for educational research.</p><p id="Par21" class="Para">By articulating the specific challenges for improving K-12 mathematics education to a broad and multidisciplinary community of psychology, education, and computer science researchers, leaders spanning these fields can collaboratively and competitively propose and conduct experiments within ASSISTments. This work can occur at an unprecedentedly precise level and large scale, allowing for the design and evaluation of different teaching strategies and rich measurement of student learning outcomes in real time, at a fraction of the cost, time, and effort previously required within K-12 research. While leading to advancements in the field through peer-reviewed publication, this collaborative work simultaneously augments content and infrastructure, thereby enhancing the system for teachers and students.</p><section id="Sec7" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Pathways for Student Support Provide Potential for Crowdsourced Contributions</h3><div id="Par22" class="Para">Previous work has aptly described feedback as “information provided by an agent (e.g., teacher, peer, book, parent, self, experience) regarding aspects of one’s performance or understanding” (Hattie and Timperley <span class="CitationRef"><a href="#CR12">2007</a></span>). Students may receive one of many types of feedback within an ASSISTments assignment, depending on settings selected by the content designer (i.e., a teacher or researcher). The most basic form of support is <em class="EmphasisTypeItalic ">correctness feedback</em>; students are informed if they are correct or incorrect when they answer each question (this feature can be shut off by placing questions in ‘test’ mode when necessary). When more elaborate feedback is desired, questions may include <em class="EmphasisTypeItalic ">mistake messages</em> created by the content author, or sourced from teachers and classes that have isolated “common wrong answers.” These messages are automatically delivered to a student in response to particular mistakes, as shown in Fig. <span class="InternalRef"><a href="#Fig1">1</a></span>. Additionally, elaborate feedback can come in the form of on-demand <em class="EmphasisTypeItalic ">hints</em> that must be requested by the student and are presented sequentially (i.e., students may see the option “Show hint 1 of 3”). Hints are typically presented with increasing specificity before presenting the student with the correct answer (the “Bottom Out Hint”), allowing the student to move on to the next problem in the assignment rather than getting stuck indefinitely. Alternatively, ASSISTments offers a form of elaborate feedback that is typically used to present worked examples, or to break a problem down into smaller, more solvable sub-steps. This type of feedback is called <em class="EmphasisTypeItalic ">scaffolding</em>, and is presented when the student makes an incorrect response or requests that the problem be broken down into steps. A comparison of hint feedback and scaffolding is presented in Fig. <span class="InternalRef"><a href="#Fig2">2</a></span>.<figure class="Figure" id="Fig1"><div class="MediaObject" id="MO1"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig1_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig1_HTML.gif" alt="Fig. 1" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1</span> <p class="SimplePara">An example of a <em class="EmphasisTypeItalic ">mistake message</em>. This type of feedback responds with tailored information that pinpoints exactly where the student made a mistake. If the student is unable to arrive at the correct answer with this guidance, standard hints are also available (note the “Show hint 1 of 3” button). The steps shown trace through the student’s probable solution path to isolate and correct the misunderstanding. In this example, the student was on the right track with steps 1 and 2, but incorrectly attributed the negative sign to his or her solution</p> </div></figcaption></figure> <figure class="Figure" id="Fig2"><div class="MediaObject" id="MO2"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig2_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig2_HTML.gif" alt="Fig. 2" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 2</span> <p class="SimplePara">A comparison of Hints and a Scaffold within an identical problem. Note that three hints are shown on the left, as requested by the student. On the right, the student provided an incorrect response and was automatically given a scaffold with a worked example on how to solve a similar problem. If the student is unable to answer this sub-step they can choose to have the answer revealed and move on to the next portion of the main problem, presented as a second scaffold</p> </div></figcaption></figure> </div><p id="Par23" class="Para">A meta-analysis of 40 studies on item-based feedback within computer-based learning environments recently suggested that elaborated feedback, or that providing a student with information beyond the accuracy of his or her response, is considerably helpful for student learning, reporting overall effect sizes of 0.49 (Van der Kleij et al. <span class="CitationRef"><a href="#CR38">2015</a></span>). To root this theory in ASSISTments terminology, elaborated feedback would include <em class="EmphasisTypeItalic ">mistake messages</em>, <em class="EmphasisTypeItalic ">hints</em>, and <em class="EmphasisTypeItalic ">scaffolds</em>, but not <em class="EmphasisTypeItalic ">correctness feedback</em>. It is also likely that the three types of elaborated feedback available within ASSISTments provide students with differential learning benefits, as they function differently with regard to timing and content specificity. Van der Kleij et al.’s (<span class="CitationRef"><a href="#CR38">2015</a></span>) examination of three previous meta-analyses revealed a gap in feedback literature: although feedback has been shown to positively impact learning, not all feedback provides the same impact. As such, it is possible that providing the worked solution for a problem is more beneficial to students than providing less specific hints. When considering learnersourcing, the type of feedback collected from a student, as well as its quality, should be taken into consideration as moderating the subsequent learning of other students that receive that content.</p><div id="Par24" class="Para">Figure <span class="InternalRef"><a href="#Fig3">3</a></span> depicts a well-established model of learning from feedback, as proposed by Bangert-Drowns et al. (<span class="CitationRef"><a href="#CR5">1991</a></span>). Within this model, students begin at an initial knowledge state (the dashed circle), and when presented with a question, practice the information retrieval required to form a response. The student then receives feedback regarding their response that he or she can use to evaluate their response and adjust their knowledge accordingly. This process is iterative with each question, beginning again at the student’s adjusted knowledge state (the dashed circle). This model is worthy of attention when designing adaptive learning technologies because the type of feedback supplied after each item will affect the learning process considerably. We present this model because it further highlights the risk of sourcing feedback from learners. If a learnersourced contribution is incorrect, or of extremely low quality, the contribution should not be presented to other students as feedback. It is crucial that learnersourced contributions only be displayed as credible feedback when it is clear that they produce measureable gains in students’ knowledge state. Later in this article, we propose that it is possible to determine the effectiveness of learnersourced contributions through randomized controlled experimentation and the use of sequential design.<figure class="Figure" id="Fig3"><div class="MediaObject" id="MO3"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig3_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig3_HTML.gif" alt="Fig. 3" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 3</span> <p class="SimplePara">Model of learning from feedback as proposed by Bangert-Drowns et al. (<span class="CitationRef"><a href="#CR5">1991</a></span>). Students begin at an initial knowledge state (dashed circle). When presented an item, information retrieval occurs and the student forms a response. Through feedback, the student evaluates his or her response and adjusts their knowledge accordingly. The process begins again at the student’s adjusted knowledge state</p> </div></figcaption></figure> </div><div id="Par25" class="Para">While students using ASSISTments benefit from the aforementioned elaborated feedback, teachers benefit from a variety of actionable reports on students’ progress. An example of an item report, the most commonly used report within ASSISTments, is shown in Fig. <span class="InternalRef"><a href="#Fig4">4</a></span>. This report has a column for each problem (i.e., “item”) and a row for each student, along with quantitative data tracking student and class performance. The first response logged by each student is provided for each problem, and teachers are able to monitor feedback usage and assignment times. Teachers often use the item report in the classroom as a learning support because it provides actionable data. The report can be anonymized, as shown in Fig. <span class="InternalRef"><a href="#Fig4">4</a></span>, which randomizes student order and hides student names for judgment free in-class use. This report allows instructors to pinpoint which students are struggling and which problems need the most attention during valuable class time. The common wrong answers featured in this report are especially important in helping instructors diagnose students’ misconceptions. They are shown in the third row of the table in Fig. <span class="InternalRef"><a href="#Fig4">4</a></span>.<figure class="Figure" id="Fig4"><div class="MediaObject" id="MO4"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig4_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig4_HTML.gif" alt="Fig. 4" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 4</span> <p class="SimplePara">An item report that shows the first three problems and the first three students from a larger class and assignment. Each column represents a problem and each row represents a student. Each item has a percent correct, and if applicable, a common wrong answer. In the student row, the student average and first attempt for each problem is reported. For example, the second student answered the first problem incorrectly (he or she said 1/9^10) and the second and third problems correctly on the first attempt. Finally the “+feedback” link affords the teacher the opportunity to write a <em class="EmphasisTypeItalic ">mistake message</em> for the common wrong answer displayed</p> </div></figcaption></figure> </div><p id="Par26" class="Para">From this type of report, teachers and students can see the percentage of students who answered the problem with a particular wrong answer (common wrong answers are those that at least three students made if representative of more than 10 % of the students in the class). In Fig. <span class="InternalRef"><a href="#Fig4">4</a></span>, only 27 % of the students answered the first problem correctly, leaving 73 % answering incorrectly. About half of the students who had an incorrect answer shared a common misconception and answered 1/9^10. This problem seems worthy of class discussion. There is also a “+feedback” link available for teachers to write a <em class="EmphasisTypeItalic ">mistake message</em> for students who attempt this problem in the future, tailoring feedback based on the misconception displayed. Many teachers work through this process with their students, helping them to learn why the misconception is incorrect and how to explain the error to another student. This practice is what makes us believe that it is possible to learnersource feedback within systems like ASSISTments. The benefits of this type of learnersourcing would be both immediate (i.e., students learn to explain their work and pinpoint misconceptions) and long lasting (i.e., students that attempt this problem in the future can access elaborate feedback that targets their misconceptions).</p></section><section id="Sec8" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">The Potential Role of Video in Crowdsourced Contributions</h3><p id="Par27" class="Para">Within ASSISTments, and in many similar adaptive learning platforms, content and feedback are facing a digital evolution. The recent widespread availability of video has spearheaded a variety of intriguing innovations in instruction. Projects like MOOCs (Massive Online Open Courses) and MIT’s OpenCourseWare™ have exposed students to didactic educational videos on a massive scale. Video lectures can be created by the best lecturers around the world and provided to anyone, allowing professors that were once a powerful resource to a limited audience to now impact any willing learner. These lectures can reach very remote parts of the world and can be accessed by those that would otherwise never have the opportunity to attend a world-class university. The universal power of the video lecture suggests that there is a “time for telling” (Schwartz and Bransford <span class="CitationRef"><a href="#CR34">1998</a></span>), and that eager learners can use technology to access the knowledge of experts and understand the bulk of the story.</p><p id="Par28" class="Para">However, many learners require more than just the storyline; students often need reinforcement and support while practicing what they have learned. We advocate for the use of video beyond lectures and into the realm of short tutorial strategies as lecturing is only a small portion of an instructor’s job that can be captured on video. By only focusing on lectures, thousands of students lose out on unique explanations and extra help that can be provided through individually tailored tutoring. The greatest teachers spend a large portion of their time tailoring instruction to a struggling student’s individual needs. Adaptive learning technologies need to consider the problem of capturing and delivering these just-in-time supports for students working in class and at home, and we argue that videos offer a starting point.</p><p id="Par29" class="Para">When ASSISTments first began, all tutorial strategies were presented using rich text. However, with content authors and student users gaining more prevalent access to video, both in the classroom and at home, ASSISTments has recently experienced an increase in volume of video explanations. Recent technological advances have made it easy for almost anyone to create and access video as support for learning. The platform has responded by making it easier for users to create videos while working within particular problems. The ASSISTments iPad application has recently been upgraded to include a built-in feature that allows users to record Khan Academy style “pencasts” (a visual walkthrough of the problem with a voice over explanation) while working within a problem. In the near future, the app will allow for these recordings to be uploaded to YouTube and stored within our database as a specific tutorial strategy for that problem. Although this linking system is still under development, the use of video within ASSISTments is already expanding through more traditional approaches to video collection and dissemination. Teachers have started to record their explanations, either in the form of a pencast or by recording themselves working through a problem on a white board, uploading the content to a video server, and linking the content to problems or feedback that they have authored. In the past year, ASSISTments has witnessed the use of videos as elaborate explanations (i.e., <em class="EmphasisTypeItalic ">hints</em>, <em class="EmphasisTypeItalic ">scaffolds</em>), as <em class="EmphasisTypeItalic ">mistake messages</em> to common wrong answers, and even for instruction as part of the problem body.</p><div id="Par30" class="Para">But why would the production of video by crowds of teachers (or even students) be helpful? Consider the following use case:<blockquote class="BlockQuote"> <p id="Par31" class="Para">A tutor is holding an after school session for five students who need extra help as they prepare for their math test. The tutor circulates around the small classroom, working with each student while referencing an ASSISTments item report on her iPad. She notices that one of the students answered a problem incorrectly and that his solution strategy includes a misconception about the problem. While tutoring him through the mistake, the tutor uses the interface within the ASSISTments app to record the help session, explaining where the student went wrong and how to reach the correct solution (essentially a conversational <em class="EmphasisTypeItalic ">mistake message</em>). The recording includes both an auditory explanation and a visual walkthrough of the problem as the tutor works through the misconception. The explanation takes about 20 seconds to provide, but because it has been captured, it must only be provided once. Following this instance of helping the student, the tutor quickly uploads her video to YouTube and links the material to the current problem. Within five minutes, another student at the extra help session reaches the same problem and tries to solve it using the same misconception. The newly uploaded feedback video is provided as a <em class="EmphasisTypeItalic ">mistake message</em> and the student is able to correct her own error by watching the video and attempting the problem again. Meanwhile, the tutor is able to help a third student on a different problem, rather than having to provide that first help message repetitively.</p> </blockquote> </div><p id="Par32" class="Para">This use case is the perfect embodiment of the vision that ASSISTments holds for the future of adaptive tutoring. The process does not exclude the human tutor from the feedback process, but rather harnesses the power of explanations given <em class="EmphasisTypeItalic ">once</em> to help students across <em class="EmphasisTypeItalic ">multiple</em> instances. We have purposely used the noun “tutor” here rather than “teacher” to signify that students may also be able to provide video feedback to help their peers through tough problems. By using this approach iteratively across many problems, or to collect numerous contributions for a particular problem, we argue that adaptive learning technologies can expand their breadth of tutoring simply by accessing the metacognitive processes already occurring within the crowd.</p><p id="Par33" class="Para">How can we convince teachers (and students) that the process of collecting feedback and building a library of explanations is useful? Suppose that the goal is to collect feedback from various users to expand the library of <em class="EmphasisTypeItalic ">mistake messages</em> to cover every common wrong answer for every problem used within remedial Algebra 1 mathematics courses. If we consider problems from only the top 30 basic Algebra 1 math textbooks in America, estimating 3000 questions per book, it leaves a total of 90,000 questions requiring feedback. High quality teachers across the country have already generated explanations to many of these problems, but they have been lost on individual students rather than recorded and banked for later use by all students. If every math teacher in the country were to explain five math questions per day, roughly 30 million explanations would be generated per year. Even if just one out of every 300 instructors captured an explanation, feedback would be collected for all 90,000 questions within a single year. Students working through these problems could also be tasked with contributing by asking them to “show their work” on their nightly homework (a process that many teachers already require) or capturing in-class discussions surrounding common misconceptions. By implementing crowdsourcing, perhaps as described here through the collection of video feedback, adaptive learning technologies can potentially access rich user content that would otherwise be lost.</p></section><section id="Sec9" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Guiding the Crowd</h3><p id="Par34" class="Para">We anticipate that in the coming years, adaptive learning technologies will incorporate mechanisms for interactivity in eliciting contributions at scale, or <em class="EmphasisTypeItalic ">directed</em> crowdsourcing (Howe <span class="CitationRef"><a href="#CR14">2006</a></span>). In our platform, we are hoping to achieve this by extending ASSISTments’ existing commenting infrastructure, which already provides teachers and researchers with the ability to interact with learners. By leveraging this system, we anticipate allowing learners to “show their work,” or provide elaborate feedback to peers that can be delivered as <em class="EmphasisTypeItalic ">hints</em>, <em class="EmphasisTypeItalic ">scaffolds</em>, or <em class="EmphasisTypeItalic ">mistake messages</em>. This process takes a complex task (content creation) and dilutes it into elements common to traditional mathematics homework. Crowdsourcing simple tasks requires a much different framework than that required for solving complex problems (Saxton et al. <span class="CitationRef"><a href="#CR33">2013</a></span>). By scaling down the task requested of each learner, the process of learnersourcing becomes much more viable. We suggest that other adaptive learning technologies seeking to implement crowdsourcing consider task complexity and how to best access the ‘mind of the crowd.’</p><div id="Par35" class="Para">Currently within ASSISTments, each time a student works on a problem or is provided a <em class="EmphasisTypeItalic ">hint</em>, they are also provided a link from which they can write a comment. Students’ comments are collected and delivered both to the student’s teacher and to the problem’s author, as shown in Fig. <span class="InternalRef"><a href="#Fig5">5</a></span>. Teachers are able to act on comments by helping students individually, while content authors (if not the teacher) are able to use the comments (which have been anonymized) to enhance the quality of their questions. Students working within ASSISTments have already written 80,000 comments while solving roughly 20 million problems within the last five years. The commenting infrastructure includes a pull down menu as a sentence starter (see Fig. <span class="InternalRef"><a href="#Fig6">6</a></span>) as well as a text field where students can provide their comment. Students use this feature to request assistance, to communicate their confusion, or to provide input on the question or answer (as shown in Fig. <span class="InternalRef"><a href="#Fig5">5</a></span>). It is possible that based on the depth of their understanding, asking students to “show their work” through a commenting structure may not be helpful to the student providing the contribution (Askey <span class="CitationRef"><a href="#CR3">1999</a></span>), but that the worked solution would ultimately prove insightful for other students when presented as elaborated feedback.<figure class="Figure" id="Fig5"><div class="MediaObject" id="MO5"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig5_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig5_HTML.gif" alt="Fig. 5" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 5</span> <p class="SimplePara">Comments from users on specific problems. Some of the comments are routine while others give the content author genuinely helpful information. This commenting infrastructure could be built out to allow students to “show their work” or to upload useful videos that would subsequently become <em class="EmphasisTypeItalic ">hints</em>, <em class="EmphasisTypeItalic ">scaffolds</em>, or <em class="EmphasisTypeItalic ">mistake messages</em> for their peers</p> </div></figcaption></figure> <figure class="Figure" id="Fig6"><div class="MediaObject" id="MO6"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig6_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig6_HTML.gif" alt="Fig. 6" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 6</span> <p class="SimplePara">The current structure for commenting within ASSISTments. Students that want to leave a comment select from the pull down menu first, then type in a more specific comment</p> </div></figcaption></figure> </div><div id="Par36" class="Para">The goal for the future of ASSISTments is to use a similar infrastructure to learnersource feedback. We hope to harness the power of YouTube, or similar video servers, alongside ASSISTments problem content while using sequential design and developing multi-armed bandit algorithms to aid in subsequent feedback delivery (discussed in a later section). This approach will build off of functionalities that already exist within the ASSISTments platform, but it will allow users to efficiently create and add feedback to the system. Figure <span class="InternalRef"><a href="#Fig7">7</a></span> depicts a mockup of an alternate crowdsourcing interface, distinct from the commenting infrastructure, that could allow content authors to easily create and link elaborate feedback to problems in the form of <em class="EmphasisTypeItalic ">mistake messages</em>. This environment offers a more in-depth approach that seeks to source content from domain experts (i.e., teachersourcing) rather than learners. In Fig. <span class="InternalRef"><a href="#Fig7">7</a></span>, the content author is informed of three common wrong answers and given the space to respond accordingly to each scenario. The Figure shows that 30 % of students responded “-20,” although the correct answer would be “-16.” In response, the content author recorded and linked a YouTube video with tutoring specific to the error. The content author then uploaded a separate video link for the 22 % of students that responded with “20” as a common wrong answer. At the bottom of Fig. <span class="InternalRef"><a href="#Fig7">7</a></span>, the “explanation” section allows the content author to add a more general comment or video that offers elaborate feedback as an on-demand <em class="EmphasisTypeItalic ">hint</em>. When students tackle this problem in the future, those that make common wrong answers will receive tailored feedback, while those that request a hint will receive the general explanation. This approach to crowdsourcing is more adept to teachers and content authors, as they provide the domain expertise required to tease out the misconceptions behind common wrong answers. As such, we suggest that the AIED community consider teachersourcing (or crowdsourcing from domain experts) independently from learnersourcing, rather than considering all users as part of the same crowd.<figure class="Figure" id="Fig7"><div class="MediaObject" id="MO7"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig7_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig7_HTML.gif" alt="Fig. 7" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 7</span> <p class="SimplePara">A mockup presenting an infrastructure for crowdsourcing tutorial strategies from domain experts. The problem content is stated at the top of the image. The user is able to create video or text feedback tailored to the three common wrong answers and is also provided the option to create a more generic explanation</p> </div></figcaption></figure> </div><p id="Par37" class="Para">While our schematics provide insight into how the actual process of crowdsourcing could work within an online learning platform, we are left with questions about how to learn which contributions are the most useful, for which learners, and under what contexts? We do not propose that the approaches presented here are the only methods for collecting student and teacher contributions, nor are we claiming that ASSISTments will be the only platform capable of these types of crowdsourcing. In the present work, we simply discuss the paths taken by the ASSISTments team to build interfaces to collect user explanations and leverage those contributions as feedback content. In the next section, we discuss a variety of randomized controlled trials that have been conducted within ASSISTments in an attempt to theorize on some of these important issues. We follow this discussion with an outline of our approach to delivering personalized content and feedback using sequential design and multi-armed bandit algorithms.</p></section></div></section><section id="Sec10" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading">Evaluating Crowdsourced Content via Randomized Controlled Experiments</h2><div class="content"><p id="Par38" class="Para">What rigorous options are available to evaluate the contributions made by the crowd? ASSISTments is unique in the technological affordances it provides for randomized experiments that compare the effects of alternative learning methodologies on quantifiable measures of learning (Williams et al. <span class="CitationRef"><a href="#CR48">2015b</a></span>). Experimental comparisons can therefore be used within the platform to evaluate the relative value of crowdsourced alternatives, just as they are used to adaptively improve and personalize other components of educational technology (Williams et al. <span class="CitationRef"><a href="#CR45">2014</a></span>). The promise of this approach is reinforced by numerous studies within ASSISTments that have already identified large positive effects on student learning, by varying factors like the type of feedback provided on homework (Mendicino et al. <span class="CitationRef"><a href="#CR26">2009</a></span>; Kelly et al. <span class="CitationRef"><a href="#CR18">2013</a></span>; Kehrer et al. <span class="CitationRef"><a href="#CR17">2013</a></span>). A series of similar experiments currently serve as a proof of concept for various iterations of teachersourcing and learnersourcing elaborate feedback.</p><section id="Sec11" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Comparing Video Feedback to Business as Usual</h3><div id="Par39" class="Para">Ostrow and Heffernan (<span class="CitationRef"><a href="#CR29">2014</a></span>) inspired the use of video feedback by designing a randomized controlled experiment to examine the effectiveness of various feedback mediums. This study sought to examine the effects on learning outcomes if identical feedback messages were presented using short video snippets. Student performance and response time were analyzed across six problems pertaining to the Pythagorean theorem. As shown in Fig. <span class="InternalRef"><a href="#Fig8">8</a></span>, feedback was matched across delivery mediums. All students had the opportunity to receive both text and video feedback during the course of the assignment, but only saw feedback if they requested assistance or if they answered a problem incorrectly. Learning gains were examined on the second question across students who received feedback on the first question (<em class="EmphasisTypeItalic ">n</em> = 89). Video feedback improved student performance on the next question, although results were not statistically significant (two-tailed, <em class="EmphasisTypeItalic ">p</em> = 0.143). Still, results suggested a moderate effect size (0.32), and it is likely that the finding would grow statistically significant with an increase in power. Following the problem set, students were asked a series of survey questions to judge how they viewed the addition of video to their assignment. Based on self-report measures, 86 % of students found the videos at least somewhat helpful and 83 % of students wanted video in future assignments. Multiple problem sets in differing math domains have since been modified to include video feedback in an attempt to replicate these findings; analyses are not yet available. The results of this study, coupled with the ability to easily record and upload video content within ASSISTments, leave our team confident that video feedback can be implemented as viable crowdsourced content.<figure class="Figure" id="Fig8"><div class="MediaObject" id="MO8"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig8_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig8_HTML.gif" alt="Fig. 8" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 8</span> <p class="SimplePara">Text and Video Feedback conditions as experienced by students (Ostrow and Heffernan <span class="CitationRef"><a href="#CR29">2014</a></span>). Isomorphic problems featured matched content feedback across mediums, and struggling students showed greater benefits from receiving video feedback</p> </div></figcaption></figure> </div></section><section id="Sec12" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Comparing Contributions from Different Teachers: Proof of Concept</h3><div id="Par40" class="Para">Selent and Heffernan (<span class="CitationRef"><a href="#CR35">2015</a></span>) took video feedback a step further to try to understand the potential benefits of crowdsourced <em class="EmphasisTypeItalic ">mistake messages</em> made by domain experts. These messages were made by a teacher that now works as part of the ASSISTments team, following a structure similar to that depicted in Fig. <span class="InternalRef"><a href="#Fig7">7</a></span> as a proof of concept. The goal of this work was to determine if video tutoring used as <em class="EmphasisTypeItalic ">mistake messages</em> for common wrong answers, paired with access to the correct answer through a “Bottom Out Hint,” would prove more effective than just providing students with the correct answer. As shown in Fig. <span class="InternalRef"><a href="#Fig9">9</a></span>, each video was 20–30 seconds in length, offering a single, tailored message to misconceptions students might have when solving one-step equation problems. Students in the control group received a problem set featuring feedback that was restricted to the correct answer, to keep them from getting stuck on a problem. Those in the experimental condition received the same problem set with feedback altered to include tailored video mistake messages. These videos explained the process the student had used to arrive at their incorrect answer and how to return to the correct solution path. In a sample of 649 students (<em class="EmphasisTypeItalic ">n</em> control = 328, <em class="EmphasisTypeItalic ">n</em> experimental = 321), no significant differences were observed in completion rates for the assignment, the number of problems required for completion, or the accuracy and attempt count on the next question following a student’s initial incorrect response (i.e., following their experience of either a video message or the answer). Thus, while the addition of teacher videos to realign common misconceptions was not <em class="EmphasisTypeItalic ">harmful</em> to student learning, this study did not prove that video was helpful when used as mistake messages. These null findings may be due in part to the limited sample of students that received tailored messaging based on common wrong answers. Still, this study suggested that an infrastructure like that depicted in Fig. <span class="InternalRef"><a href="#Fig7">7</a></span> would be viable to teachersource feedback content.<figure class="Figure" id="Fig9"><div class="MediaObject" id="MO9"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig9_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig9_HTML.gif" alt="Fig. 9" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 9</span> <p class="SimplePara">Teacher created video used as a mistake message tailored to the common wrong answer of “-9.” In the 31 second clip, the teacher notes that the student added 9 to both sides when he or she should have subtracted 9 from both sides. Multiple videos, or similar feedback delivered using alternative mediums, can be teachersourced for use as elaborate feedback</p> </div></figcaption></figure> </div></section><section id="Sec13" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Comparing Contributions from Students: Proof of Concept Designs</h3><div id="Par41" class="Para">One of the more unique studies currently running within ASSISTments considers learnersourced contributions in a controlled environment to determine which contribution leads to greater learning. This randomized controlled experiment examines two versions of feedback for the same problem on elapsed time, sourced from two different students. These students were not directed in their explanations, they were simply asked to “show their work” in solving the problem to benefit their peers that may still be struggling. As shown in Fig. <span class="InternalRef"><a href="#Fig10">10</a></span>, the resulting explanations were rather different when students were asked to determine the amount of elapsed time between 7:30 am and 4:15 pm. Student A (left) chose to break down the elapsed time across a number line, while Student B (right) used a clock face to show the progression of time. While results are not yet available for this work, we present this research design as proof of concept for a basic method of testing the effectiveness of learnersourced contributions. This design can easily be scaled to consider a much larger crowd, comparing numerous instances of elaborate feedback from student users. Of course, teachers would need to abide by the necessary permission requirements at the school level in order for students to be recorded in the classroom environment, but we see this as a minor obstacle within learnersourcing feedback.<figure class="Figure" id="Fig10"><div class="MediaObject" id="MO10"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig10_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig10_HTML.gif" alt="Fig. 10" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 10</span> <p class="SimplePara">Student A solves an elapsed time problem using a method based on measuring steps between chunks of time that have passed. Student B solves the same problem using a method based on the way hands move around a clock face. Through a randomized controlled design, we hope to determine which feedback instance leads to greater student learning</p> </div></figcaption></figure> </div><p id="Par42" class="Para">A second, more elaborate design, has also been implemented to examine the quality and effectiveness of learnersourced feedback provided as <em class="EmphasisTypeItalic ">hints</em>. Students in an AP Chemistry class were randomly assigned problem sets on two unrelated topics following an AB crossover design. For the first topic the student experienced, they were required to show and explain their work. For the second topic, they were simply required to provide an answer. Thus, half of the sample created explanations for Topic A and provided answers for Topic B, while the other half created explanations for Topic B and provided answers for Topic A. Before the crossover, the strongest student explanations were selected by the teacher and made available to students as they attempted to provide answers for the alternate topic. As a control, a portion of students continued to receive the text hints traditionally provided by ASSISTments. A posttest was to be conducted to determine if writing explanations lead to better learning than providing answers alone and to determine whether learnersourced contributions lead to better learning than traditional text hints. For this iteration of the study, the posttest was not ultimately assigned to the sample population and therefore results were not substantiated. However, this study served as a basis for a design that can be reused to assess the quality and usefulness of learnersourced feedback.</p></section><section id="Sec14" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Collective vs. Individual Teachers’ Contributions: “Patchwork Quilts” of Feedback</h3><div id="Par43" class="Para">In 2014, seven teachers were funded by a grant initiative to increase the amount of video feedback within ASSISTments with the intention of establishing a bank of crowdsourced explanations to use in various randomized controlled research designs. Numerous studies are currently running in ASSISTments to investigate the effects of being taught by multiple teachers. Versions of what we term the “Patchwork Quilt” design have been built to present feedback videos from mixes of two or more teachers across a set of problems. For instance, in the design shown in Table <span class="InternalRef"><a href="#Tab1">1</a></span>, students are randomly assigned to a “Teacher” condition or to the control (displayed across rows). Three teachers (Teacher A, B, &amp; C) were asked to create video feedback for three isomorphic problems (displayed across columns). Videos from Teacher A and Teacher B are shown in Fig. <span class="InternalRef"><a href="#Fig11">11</a></span> for comparison. Although both teachers approached video creation using pencasts, the formats are noticeably different. Just as the design in the previous section explored the effectiveness of learnersourced contributions, this randomized controlled design explores the effectiveness of teachersourced feedback at a small scale (<em class="EmphasisTypeItalic ">n</em> = 3). Comparison of learning outcomes will be possible in these designs by implementing posttests following instances of crowdsourced feedback.<div id="Tab1" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 1</span> <p class="SimplePara">The “Patchwork Quilt” design. Across three isomorphic problems, students are randomly assigned to receive video feedback from Teacher A, Teacher B, Teacher C, or a mix of all three teachers. The control condition features the text feedback traditionally provided within ASSISTments for comparison. Through a posttest following problem 3, differences in learning outcomes can be measured to determine the effectiveness of teachersourced content</p> </div></div><div class="u-scroll-horizontal"><div class="MediaObject" id="MO11"> <a href="https://static-content.springer.com/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Tab1_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://static-content.springer.com/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Tab1_HTML.gif" alt="" /></a> </div></div></div> <figure class="Figure" id="Fig11"><div class="MediaObject" id="MO12"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig11_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig11_HTML.gif" alt="Fig. 11" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 11</span> <p class="SimplePara">Videos created by Teacher A and Teacher B on isomorphic problems. Both questions feature fraction addition with common denominators. The teachers use different teaching approaches and slightly different video styles to present elaborate feedback</p> </div></figcaption></figure> </div></section></div></section><section id="Sec15" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading">Motivating Participation in Learnersourcing</h2><div class="content"><p id="Par44" class="Para">As we crowdsource explanations from students to enrich the content in ASSISTments, it is necessary to ask why a student would want to provide an explanation as the time and effort required is nontrivial. Within ASSISTments’ implementation of learnersourcing, we have devised several methods to incentivize student participation. Our goal is to provide incentives that encourage students to supply a high volume of high quality explanations.</p><p id="Par45" class="Para">The simplest ‘incentive’ is to do nothing other than provide students the ability to create explanations and notify them that their contributions will be shared with their peers. This approach would be voluntary and would not require a reward structure. We believe that this approach would show limited success simply based on altruism.</p><p id="Par46" class="Para">A stronger incentive would require the design of a rating system that students could use to rate the contributions of their peers. Students that write high quality explanations would be highly rated by their peers, while those that write low quality explanations would receive lower ratings. This approach to incentivization is also voluntary in nature and implements only a social reward structure. This approach also allows room for error as it calls on crowd collaboration to designate contribution quality (Saxton et al. <span class="CitationRef"><a href="#CR33">2013</a></span>) and it may present social risks if contributions are directly linked to students.</p><p id="Par47" class="Para">Another potential incentivization is to get students to explain their mistakes by providing an extra opportunity to earn credit within an assignment. While this approach would source a higher volume of feedback messages, it could lower the quality of contributions. How do we create an environment where students both want to provide feedback and are likely to provide useful feedback? One of the basic types of problem sets within ASSISTments is the Skill Builder. Skill Builders are assignments that have an exit requirement of <em class="EmphasisTypeItalic ">n</em> problems right in a row, with 3 problems set as the default. A common complaint from students who complete Skill Builder assignments is that they will answer two problems correctly, and then make a mistake on the third, thereby resetting their progress. Data mining has suggested that a student that gets two consecutive correct answers has an 84 % chance of correctly answering the third question (Van Inwegen et al. <span class="CitationRef"><a href="#CR39">2015</a></span>). A slight difference exists between the student that accurately answers the first two questions in the assignment (88.5 % chance of accurately answering the third problem) and the student that achieves two consecutive correct answers at a later point in their assignment (82.6 % chance of accurately answering the next problem). With these probabilities in mind, problem sets can be manipulated to allow students a second chance to answer a third consecutive question, at the cost of providing a <em class="EmphasisTypeItalic ">mistake message</em> to assist their peers. The goal behind adaptive learning technologies providing second chance problems in the context of learnersourcing also benefits evaluating the strength of contributions: if the student is able to answer the “redo,” there is a high probability that the feedback they provide will be useful to other students. The student was able to self-correct and explain their misconception. On the other hand, students that answer the “redo” incorrectly are not likely to provide useful feedback. Performance on a second chance problem can therefore serve as an initial curator for weeding out feedback content that has low efficacy or accuracy. Providing students an opportunity to learn from their mistakes has been shown to improve learning (Attali and Powers <span class="CitationRef"><a href="#CR4">2010</a></span>), and the process serves as a viable way to elicit feedback from students in the context of assignments within adaptive learning technologies.</p><p id="Par48" class="Para">A more mandatory incentive is to <em class="EmphasisTypeItalic ">force</em> students to write explanations for the problems that they solve as part of a predefined grading rationale. Although this may seem demanding, it is traditional practice in most classrooms; teachers almost always require students to show their problem solving process in order to receive full credit for their assignments. Without proof that a student has worked through the problem on their own, it is impossible to know how he or she arrived at an answer and whether or not they simply copied a peer. This incentivization integrates a student’s normal workflow with the creation of explanations. Expanding on this idea, teachers could have the ability to edit and improve upon student explanations by grading the work, tapping into traditional teacher grading workflow.</p><p id="Par49" class="Para">Regardless of incentivization, in order to implement learnersourcing on a larger scale in our world (i.e., from all students, across all content within ASSISTments), it is still necessary for our team to design a proper crowdsourcing infrastructure for use by teachers and students. This goal sparked the birth of PeerASSIST, a feature currently being developed to allow students to provide assistance to their peers through explanations and mistakes messages.</p></div></section><section id="Sec16" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading">IMPLEMENTING LEARNERSOURCED FEEDBACK WITHIN ASSISTMENTS: PEERASSIST</h2><div class="content"><div id="Par50" class="Para">Since ASSISTments began, the standard method of instruction has included hints or scaffolding to help students solve problems or to break problems down into smaller steps. This approach will be overhauled by the implementation of PeerASSIST. The envisioned workflow of the new feature, as shown in Fig. <span class="InternalRef"><a href="#Fig12">12</a></span>, begins as an option on the tutor interface; a button that allows the student to “Explain How to Solve This Problem.” When the student clicks on this button, an input window opens prompting the student for feedback. The content generated by the student might be a worked example of the problem, an explanation regarding the solution or a common wrong answer, hints regarding the proper approach, or even a motivational message to encourage their peer. When the student submits his or her feedback, it is linked to the current problem and sent to the ASSISTments database. When another student in the same class begins the problem, an additional option will be added to the second student’s tutor interface that will “Show My Classmate’s Explanation.” If the student clicks on this button, PeerASSIST will randomly provide a piece of student generated feedback for that problem (it is possible that problems would accumulate multiple explanations, some better than others, that could be tested for efficacy and accuracy through random provision). Current design protocol does not allow a student to ask for peer assistance more than once per problem. However, the student can default to traditional ASSISTments assistance (hints or scaffolding) that exist for the problem.<figure class="Figure" id="Fig12"><div class="MediaObject" id="MO13"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig12_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig12_HTML.gif" alt="Fig. 12" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 12</span> <p class="SimplePara">The PeerASSIST data flow. Students generate feedback for other students. Feedback is linked to a particular problem and provided randomly to students that subsequently struggle with the same problem. Students are able to judge the feedback provided by their peers, and teachers are able to manage feedback created by their students using a management interface</p> </div></figcaption></figure> </div><p id="Par51" class="Para">Within PeerASSIST, students will also be able to voice whether or not the hints provided by their peers are helpful. Each instance of peer feedback will include “Like” and “Dislike” buttons, allowing the user to judge the efficacy and accuracy of the feedback. There will also be a “Report” button, allowing students to flag inappropriate content within peer-generated feedback to isolate that piece of content for potential removal from the system. If an instance of feedback is reported by more than one student, it will automatically be removed from the pool of explanations linked to that problem. Teachers will also be able to review and veto PeerASSIST feedback generated by their students on a page specifically designed for feedback management.</p><p id="Par52" class="Para">The remaining issue that exists within PeerASSIST is determining which explanation to display if a problem has multiple instances of student generated feedback. An obvious approach would be to randomly select an explanation to use each time a student requests peer assistance (much like the randomized controlled experimentation already presented). This approach would be easy to implement and explain. However, if a PeerASSIST explanation has been “Disliked” many times, there is little reason to continue to display that contribution. Further, the information linked to each PeerASSIST explanation has the potential go beyond “Likes” and “Dislikes.” Certain researchers may be more interested in learning specific outcomes for specific instances of feedback. Thus, the system must rely on an approach that will explore the learning outcomes brought about by student-generated feedback while supplying students the best assistance available.</p><section id="Sec17" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Algorithms for Evaluating Crowdsourced Contributions</h3><p id="Par53" class="Para">Once feedback content has been sourced, how do we deem explanations as effective? The solution is not to examine how much the explanation helps the student through the question that he or she is struggling with, but rather to consider increases in the probability that the student answers their next problem accurately, on their first attempt, without any help. This problem of managerial control is not specific to our domain and has existed for a long time in the design of experiments. In a general context the question becomes, “How many samples should we draw and which populations should the samples be drawn from?” This question was originally proposed by Herbert Robbins in his landmark paper on sequential design (Robbins <span class="CitationRef"><a href="#CR32">1952</a></span>). Sequential design of experiments occurs when the sample size is not predetermined but is a function of the samples themselves, as opposed to being fixed before an experiment is conducted.</p><p id="Par54" class="Para">There are several advantages to using sequential design. Sequential design allows for an experiment to use a fewer number of samples and allows for the experiment to end earlier. Resources such as time, money, and the number of samples required are saved. Another advantage to this approach is that if a particular condition in an experiment is detrimental, it can be avoided more efficiently. This often occurs in medical trials where a treatment is ultimately found to be harmful (Wegscheider <span class="CitationRef"><a href="#CR42">1998</a></span>). There is no reason to continue providing a harmful treatment and it is essentially unethical. Using sequential design of experiments minimizes and prevents the undue provision of harmful treatment. However, a disadvantage of sequential design is that constant significance testing throughout the course of the experiment can result in high Type-I error rates (although this can be prevented through various forms of error correction).</p><div id="Par55" class="Para">The sequential design problem is more commonly known as the multi-armed bandit story. Multi-armed bandits are presented when a person enters a casino to play a slot machine and each potential machine has a different payout rate, as depicted in Fig. <span class="InternalRef"><a href="#Fig13">13</a></span>. The player needs to determine which machine’s lever (or “arm”) to pull that will provide the greatest payout rate in order to maximize his or her profits. In this scenario, slot machines have earned the term “bandits” because regardless of payout rate, they essentially steal money from the player (Lai and Robbins <span class="CitationRef"><a href="#CR21">1985</a></span>). This problem is also known as the exploration/exploitation trade-off in the area of reinforcement learning. In this context, the gambler needs to explore various slot machines to determine which machine has the best payout, but must also exploit the machine with the best-known payout rate. Considering sequential design, the number of populations is equivalent to the number of slot machine arms that can be pulled. A sample from a chosen population is analogous to a pull on a chosen arm of a slot machine. In the context of learnersourcing within ASSISTments, the pool of content available to assign to students represents these populations (arms to pull) and a sample from the population is equivalent to assigning a piece of content to a student.<figure class="Figure" id="Fig13"><div class="MediaObject" id="MO14"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig13_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs40593-016-0094-z/MediaObjects/40593_2016_94_Fig13_HTML.gif" alt="Fig. 13" /></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 13</span> <p class="SimplePara">An example of how a multi-armed bandit algorithm can be used when crowdsourcing student explanations. In this example there are three slot machines representing three different student-generated tutoring strategies. A multi-armed bandit algorithm is run balancing exploration and exploitation to determine which of the three tutoring strategies is given to the next student</p> </div></figcaption></figure> </div><p id="Par56" class="Para">It is important that we use sequential design when assigning content to students for several reasons. The first and most important reason is to quickly filter out “bad feedback” content while exposing as few students as possible. Aside from malicious or purely erroneous content, “bad feedback” would be considered any content that results in unnecessary confusion or misinformation, which can be detected by measures of how well students perform on the next problem following feedback. It would be unethical to use design types in which we would continue to expose children to content known to be “bad.” The use of sequential design will also allow us to conduct experiments in which we do not know the amount of content or the number of students a priori. This versatility is essential in order to conduct experiments in a crowdsourcing environment, where new content and new students are continually entering the system.</p></section></div></section><section id="Sec18" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading">Lessons Learned and a Call to the Community</h2><div class="content"><div id="Par57" class="Para">Beyond the experiments presented here, additional proof of concept work has been conducted to better understand the complexities and consequences of teachersourcing and learnersourcing feedback within ASSISTments. The studies presented herein, many of which are still in progress, were not included for the consideration of particularly significant or null findings, but rather, to present the direction in which our team is moving. Many of the remaining concerns about the implementation of crowdsourcing can be explored as research questions that we pose to the AIED community for exploration across adaptive learning technologies in the coming years:<div class="OrderedList"><ol><li class="ListItem"><span class="ItemNumber">1.</span><div class="ItemContent"> <p id="Par58" class="Para">How do we ensure the accuracy of learnersourced feedback?</p> </div><div class="ClearBoth"> </div></li><li class="ListItem"><span class="ItemNumber">2.</span><div class="ItemContent"> <p id="Par59" class="Para">What is the efficacy of learnersourced feedback?</p> </div><div class="ClearBoth"> </div></li><li class="ListItem"><span class="ItemNumber">3.</span><div class="ItemContent"> <p id="Par60" class="Para">Are students willing to spend their time generating feedback for other students?</p> </div><div class="ClearBoth"> </div></li><li class="ListItem"><span class="ItemNumber">4.</span><div class="ItemContent"> <p id="Par61" class="Para">Are students willing to use feedback that has been generated by a peer?</p> </div><div class="ClearBoth"> </div></li><li class="ListItem"><span class="ItemNumber">5.</span><div class="ItemContent"> <p id="Par62" class="Para">How do we ensure the accuracy of teachersourced feedback?</p> </div><div class="ClearBoth"> </div></li><li class="ListItem"><span class="ItemNumber">6.</span><div class="ItemContent"> <p id="Par63" class="Para">What is the efficacy of teachersourced feedback?</p> </div><div class="ClearBoth"> </div></li><li class="ListItem"><span class="ItemNumber">7.</span><div class="ItemContent"> <p id="Par64" class="Para">Can crowdsourcing be implemented as an effective use of teachers and students time?</p> </div><div class="ClearBoth"> </div></li></ol></div> </div><p id="Par65" class="Para">This is by no means an exhaustive list for the community’s consideration, and it is likely fair to say that a range of possible outcomes will exist for each of these concerns spanning content domains, age ranges, and types of learners. It is possible that crowdsourcing will be useful and/or successful in certain scenarios but not in others. It is also possible that crowdsourcing will prove a more viable strategy for particular adaptive learning technologies. As we have presented here, we suggest that the community considers an approach to crowdsourcing (specifically learnersourcing) that simplifies the complex task of content creation into the simple task of having students “show their work.” The Common Core Standards for Mathematics (NGACBP and CCSSO <span class="CitationRef"><a href="#CR27">2010</a></span>) require that students are able to explain their reasoning in addition to answering questions. Thus, more and more, students are providing written explanations of their work as part of normal instruction. As exemplified by our proof of concept study designs, ASSISTments has the potential to gather teachersourced and learnersourced contributions and rigorously test their effectiveness. While our platform is somewhat novel in this regard, and much of our work is still underway, other adaptive learning technologies will also serve as excellent resources for studying crowdsourced content in the coming 25 years of AIED research.</p></div></section><section id="Sec19" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading">Closing Thoughts</h2><div class="content"><p id="Par66" class="Para">While predicting the future is an impossible task, considering the trends in amongst domains it is safe to say that the future of adaptive learning will be strongly driven by the crowd. Current technologies that rely on the crowd for expert knowledge and system expansion are prevailing, and the trend will soon spill over into educational domains. As such, we have presented our plan for bringing ASSISTments into the next quarter century while highlighting the complexities of crowdsourcing for consideration by the AIED community.</p><p id="Par67" class="Para">Especially in the realm of mathematics, students around the world have historically been required to ‘show their work’ when completing homework or answering test problems. In the age of adaptive learning technologies, these worked examples can be captured and used as powerful feedback for other, subsequently struggling students. This practice would benefit all parties: explaining a solution allows the student to solidify his or her understanding of the problem, receiving peer explanation increases motivation and employs proper solution strategies in struggling students, and the adaptive learning platform experiences perpetual evolution and expanse. Perhaps most intriguing, all of this promise stems from only minor adjustments to the workflow that is already taking place in classrooms around the world, as teachers and students use online learning platforms like ASSISTments to conduct day-to-day learning activities. Simple steps can be taken to bring adaptive learning technologies to the next level: simplifying the collection of video feedback, running randomized controlled experiments to understand what works, building out an infrastructure like PeerASSIST to capture the explanations that students are already preparing, and employing sequential design to deliver the right feedback to the right students at the right times. The crowd can be a limitless force and it is better to have teachers and students on our side and ultimately working with us rather than against or alongside us.</p><p id="Par68" class="Para">Harnessing the knowledge of the crowd will enhance adaptive learning platforms moving forward. The next 25 years within the AIED community should be marked by research that brings underlying fields together to understand best practices, establish collaborative scientific tools for the community, and integrate users through content creation and delivery. The current application of stringent research methodologies to improve learning outcomes is severely lagging what the educational research community requires. The inclusion of sound experimental design and crowdsourced content within adaptive learning systems has the potential to simultaneously produce large-scale systemic change for education reform, while advancing the collaborative knowledge of those researching AIED.</p></div></section></div><section id="Notes" class="Section1 RenderAsSection1"><h2 class="Heading">Notes</h2><div class="content"><section><h3 class="Heading">Acknowledgments</h3><p class="SimplePara">We would like to thank all the 150+ students at WPI that helped us create ASSISTments, and then do research with it. We would also like to thank NSF (0231773, 1109483, 0448319, 0742503, 1031398, 1440753, 1252297, 1316736, and 1535428), GAANN, The Spencer Foundation, The US Department of Education (R305K03140, R305A07440, R305C100024 and R305A120125), The Office of Naval Research, the Bill and Melinda Gates Foundation, and EDUCAUSE for funding the research described here. A complete list of funders is here: <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://www.aboutus.assistments.org/partners.php"><span class="RefSource">http://www.aboutus.assistments.org/partners.php</span></a></span>. Thanks to S.O. &amp; L.P.B.O. We would also like to thank the editor of this Special Issue and the three anonymous reviewers that helped to strengthen our work prior to publication.</p></section></div></section><section class="Section1 RenderAsSection1" id="Bib1" tabindex="-1"><h2 class="Heading">References</h2><div class="content"><ol class="BibliographyWrapper"><li class="Citation"><div class="CitationContent" id="CR1">Aleahmad, T., Aleven, V., and Kraut, R. (2008). Open community authoring of targeted worked example problems. In Woolf, Aimeur, Nkambou, &amp; Lajoie (eds) <em class="EmphasisTypeItalic ">Proceedings of the 9th International Conference on Intelligent Tutoring Systems</em>. Springer-Verlag. pp. 216–227.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Aleahmad%2C%20T.%2C%20Aleven%2C%20V.%2C%20and%20Kraut%2C%20R.%20%282008%29.%20Open%20community%20authoring%20of%20targeted%20worked%20example%20problems.%20In%20Woolf%2C%20Aimeur%2C%20Nkambou%2C%20%26%20Lajoie%20%28eds%29%20Proceedings%20of%20the%209th%20International%20Conference%20on%20Intelligent%20Tutoring%20Systems.%20Springer-Verlag.%20pp.%20216%E2%80%93227."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR2">Anderson, A., Huttenlocher, D., Kleinberg, J., &amp; Leskovec, J. (2012, August). Discovering value from community activity on focused question answering sites: a case study of stack overflow. In <em class="EmphasisTypeItalic ">Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</em> (pp. 850–858). ACM.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Anderson%2C%20A.%2C%20Huttenlocher%2C%20D.%2C%20Kleinberg%2C%20J.%2C%20%26%20Leskovec%2C%20J.%20%282012%2C%20August%29.%20Discovering%20value%20from%20community%20activity%20on%20focused%20question%20answering%20sites%3A%20a%20case%20study%20of%20stack%20overflow.%20In%20Proceedings%20of%20the%2018th%20ACM%20SIGKDD%20international%20conference%20on%20Knowledge%20discovery%20and%20data%20mining%20%28pp.%20850%E2%80%93858%29.%20ACM."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR3">Askey, R. (1999). Knowing and teaching elementary mathematics. <em class="EmphasisTypeItalic ">American Educator, 23</em>, 6–13.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Askey%2C%20R.%20%281999%29.%20Knowing%20and%20teaching%20elementary%20mathematics.%C2%A0American%20Educator%2C%C2%A023%2C%206%E2%80%9313."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR4">Attali, Y., &amp; Powers, D. (2010). Immediate feedback and opportunity to revise answers to open-ended questions. <em class="EmphasisTypeItalic ">Educational and Psychological Measurement</em>, <em class="EmphasisTypeItalic ">70</em>(1), 22–35.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1177/0013164409332231"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Immediate%20feedback%20and%20opportunity%20to%20revise%20answers%20to%20open-ended%20questions&amp;author=Y.%20Attali&amp;author=D.%20Powers&amp;journal=Educational%20and%20Psychological%20Measurement&amp;volume=70&amp;issue=1&amp;pages=22-35&amp;publication_year=2010"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR5">Bangert-Drowns, R. L., Kulik, C. C., Kulik, J. A., &amp; Morgan, M. T. (1991). The instructional effect of feedback in test-like events. <em class="EmphasisTypeItalic ">Review of Educational Research</em>, <em class="EmphasisTypeItalic ">61</em>, 213–238.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.3102/00346543061002213"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=The%20instructional%20effect%20of%20feedback%20in%20test-like%20events&amp;author=RL.%20Bangert-Drowns&amp;author=CC.%20Kulik&amp;author=JA.%20Kulik&amp;author=MT.%20Morgan&amp;journal=Review%20of%20Educational%20Research&amp;volume=61&amp;pages=213-238&amp;publication_year=1991"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR6">Boyd, D., &amp; Crawford, K. (2012). Critical questions for big data: provocations for a cultural, technological, and scholarly phenomenon. <em class="EmphasisTypeItalic ">Information, Communication &amp; Society</em>, <em class="EmphasisTypeItalic ">15</em>(5), 662–679.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1080/1369118X.2012.678878"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Critical%20questions%20for%20big%20data%3A%20provocations%20for%20a%20cultural%2C%20technological%2C%20and%20scholarly%20phenomenon&amp;author=D.%20Boyd&amp;author=K.%20Crawford&amp;journal=Information%2C%20Communication%20%26%20Society&amp;volume=15&amp;issue=5&amp;pages=662-679&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR7">Doan, A., Ramakrishnan, R., &amp; Halevy, A. Y. (2011). Crowdsourcing systems on the world-wide web. <em class="EmphasisTypeItalic ">Communications of the ACM</em>, <em class="EmphasisTypeItalic ">54</em>(4), 86–96.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1145/1924421.1924442"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Crowdsourcing%20systems%20on%20the%20world-wide%20web&amp;author=A.%20Doan&amp;author=R.%20Ramakrishnan&amp;author=AY.%20Halevy&amp;journal=Communications%20of%20the%20ACM&amp;volume=54&amp;issue=4&amp;pages=86-96&amp;publication_year=2011"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR8">Estellés-Arolas, E., &amp; González-Ladrón-de-Guevara, F. (2012). Towards an integrated crowdsourcing definition. <em class="EmphasisTypeItalic ">Journal of Information Science</em>, <em class="EmphasisTypeItalic ">38</em>(2), 189–200.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1177/0165551512437638"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Towards%20an%20integrated%20crowdsourcing%20definition&amp;author=E.%20Estell%C3%A9s-Arolas&amp;author=F.%20Gonz%C3%A1lez-Ladr%C3%B3n-de-Guevara&amp;journal=Journal%20of%20Information%20Science&amp;volume=38&amp;issue=2&amp;pages=189-200&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR9">Floryan, M., &amp; Woolf, B. P. (2013, January). Authoring Expert Knowledge Bases for Intelligent Tutors through Crowdsourcing. In <em class="EmphasisTypeItalic ">Artificial Intelligence in Education</em> (pp. 640–643). Springer Berlin Heidelberg.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Floryan%2C%20M.%2C%20%26%20Woolf%2C%20B.%20P.%20%282013%2C%20January%29.%20Authoring%20Expert%20Knowledge%20Bases%20for%20Intelligent%20Tutors%20through%20Crowdsourcing.%20In%20Artificial%20Intelligence%20in%20Education%20%28pp.%20640%E2%80%93643%29.%20Springer%20Berlin%20Heidelberg."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR10">Franklin, M. J., Kossmann, D., Kraska, T., Ramesh, S., &amp; Xin, R. (2011, June). CrowdDB: answering queries with crowdsourcing. In <em class="EmphasisTypeItalic ">Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data</em> (pp. 61–72). ACM.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Franklin%2C%20M.%20J.%2C%20Kossmann%2C%20D.%2C%20Kraska%2C%20T.%2C%20Ramesh%2C%20S.%2C%20%26%20Xin%2C%20R.%20%282011%2C%20June%29.%20CrowdDB%3A%20answering%20queries%20with%20crowdsourcing.%20In%20Proceedings%20of%20the%202011%20ACM%20SIGMOD%20International%20Conference%20on%20Management%20of%20Data%20%28pp.%2061%E2%80%9372%29.%20ACM."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR11">Griswold, A. (2014). How Luis Von Ahn Turned Countless Hours of Mindless Activity Into Something Valuable. Business Insider, <em class="EmphasisTypeItalic ">Strategy</em>. Retrieved on November 14, 2015, from http://www.businessinsider.com/luis-von-ahn-creator-of-duolingo-recaptcha-2014-3<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Griswold%2C%20A.%20%282014%29.%20How%20Luis%20Von%20Ahn%20Turned%20Countless%20Hours%20of%20Mindless%20Activity%20Into%20Something%20Valuable.%20Business%20Insider%2C%20Strategy.%20Retrieved%20on%20November%2014%2C%202015%2C%20from%20http%3A%2F%2Fwww.businessinsider.com%2Fluis-von-ahn-creator-of-duolingo-recaptcha-2014-3"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR12">Hattie, J., &amp; Timperley, H. (2007). The power of feedback. <em class="EmphasisTypeItalic ">Review of Educational Research.</em>, <em class="EmphasisTypeItalic ">77</em>, 81–112.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.3102/003465430298487"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=The%20power%20of%20feedback&amp;author=J.%20Hattie&amp;author=H.%20Timperley&amp;journal=Review%20of%20Educational%20Research.&amp;volume=77&amp;pages=81-112&amp;publication_year=2007"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR13">Heffernan, N., &amp; Heffernan, C. (2014). The ASSISTments ecosystem: building a platform that brings scientists and teachers together for minimally invasive research on human learning and teaching. <em class="EmphasisTypeItalic ">International Journal of Artificial Intelligence in Education</em>, <em class="EmphasisTypeItalic ">24</em>(<em class="EmphasisTypeItalic ">4</em>), 470–497.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=3178103"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1007/s40593-014-0024-x"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=The%20ASSISTments%20ecosystem%3A%20building%20a%20platform%20that%20brings%20scientists%20and%20teachers%20together%20for%20minimally%20invasive%20research%20on%20human%20learning%20and%20teaching&amp;author=N.%20Heffernan&amp;author=C.%20Heffernan&amp;journal=International%20Journal%20of%20Artificial%20Intelligence%20in%20Education&amp;volume=24&amp;issue=4&amp;pages=470-497&amp;publication_year=2014"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR14">Howe, J. (2006). The rise of crowdsourcing. Wired Magazine, 14(6), 1–4. Retrieved November 14, 2015 from <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://www.wired.com/2006/06/crowds/"><span class="RefSource">http://www.wired.com/2006/06/crowds/</span></a></span>
                        <span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationContent" id="CR15">Howe, J. (2008). <em class="EmphasisTypeItalic ">Crowdsourcing: Why the power of crowd is driving the future of business</em>. New York,: Crown Business.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20Crowdsourcing%3A%20Why%20the%20power%20of%20crowd%20is%20driving%20the%20future%20of%20business%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;author=J.%20Howe&amp;publication_year=2008"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR16">Kim, J. (2015). Learnersourcing: Improving Learning with Collective Learner Activity. MIT PhD Thesis. Retrieved from <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://juhokim.com/files/JuhoKim-Thesis.pdf"><span class="RefSource">http://juhokim.com/files/JuhoKim-Thesis.pdf</span></a></span>.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationContent" id="CR17">Kehrer, P., Kelly, K. &amp; Heffernan, N. (2013). Does immediate feedback while doing homework improve learning. In Boonthum-Denecke, Youngblood (Eds), Proceedings of the twenty-sixth international Florida artificial intelligence research society conference. AAAI Press 2013. pp 542–545.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Kehrer%2C%20P.%2C%20Kelly%2C%20K.%20%26%20Heffernan%2C%20N.%20%282013%29.%20Does%20immediate%20feedback%20while%20doing%20homework%20improve%20learning.%20In%20Boonthum-Denecke%2C%20Youngblood%20%28Eds%29%2C%20Proceedings%20of%20the%20twenty-sixth%20international%20Florida%20artificial%20intelligence%20research%20society%20conference.%20AAAI%20Press%202013.%20pp%20542%E2%80%93545."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR18">Kelly, K., Heffernan, N., Heffernan, C., Goldman, S., Pellegrino, J., &amp; Goldstein, D. S. (2013). Estimating the effect of web-based homework. In Lane, Yacef, Motow &amp; Pavlik (Eds) <em class="EmphasisTypeItalic ">The Artificial Intelligence in Education Conference</em>. Springer-Verlag. pp. 824–827.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Kelly%2C%20K.%2C%20Heffernan%2C%20N.%2C%20Heffernan%2C%20C.%2C%20Goldman%2C%20S.%2C%20Pellegrino%2C%20J.%2C%20%26%20Goldstein%2C%20D.%20S.%20%282013%29.%20Estimating%20the%20effect%20of%20web-based%20homework.%20In%20Lane%2C%20Yacef%2C%20Motow%20%26%20Pavlik%20%28Eds%29%20The%20Artificial%20Intelligence%20in%20Education%20Conference.%20Springer-Verlag.%20pp.%20824%E2%80%93827."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR19">Kittur, A., Nickerson, J. V., Bernstein, M., Gerber, E., Shaw, A., Zimmerman, J.,... &amp; Horton, J. (2013, February). The future of crowd work. In <em class="EmphasisTypeItalic ">Proceedings of the 2013 Conference on Computer Supported Cooperative Work.</em> pp. 1301–1318. ACM.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Kittur%2C%20A.%2C%20Nickerson%2C%20J.%20V.%2C%20Bernstein%2C%20M.%2C%20Gerber%2C%20E.%2C%20Shaw%2C%20A.%2C%20Zimmerman%2C%20J.%2C...%20%26%20Horton%2C%20J.%20%282013%2C%20February%29.%20The%20future%20of%20crowd%20work.%20In%20Proceedings%20of%20the%202013%20Conference%20on%20Computer%20Supported%20Cooperative%20Work.%20pp.%201301%E2%80%931318.%20ACM."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR20">Kulkarni, C., Wei, K. P., Le, H., Chia, D., Papadopoulos, K., Cheng, J., et al. (2015). Peer and self assessment in massive online classes. In H. Plattner, C. Meinel &amp; L. Leifer (Eds.), <em class="EmphasisTypeItalic ">Design thinking research</em> (pp. 131–168). Springer-Verlag Berlin Heidelberg: New York.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Kulkarni%2C%20C.%2C%20Wei%2C%20K.%20P.%2C%20Le%2C%20H.%2C%20Chia%2C%20D.%2C%20Papadopoulos%2C%20K.%2C%20Cheng%2C%20J.%2C%20et%20al.%20%282015%29.%20Peer%20and%20self%20assessment%20in%20massive%20online%20classes.%20In%C2%A0H.%20Plattner%2C%20C.%20Meinel%20%26%20L.%20Leifer%20%28Eds.%29%2C%20Design%20thinking%20research%20%28pp.%20131%E2%80%93168%29.%20Springer-Verlag%20Berlin%20Heidelberg%3A%20New%20York."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR21">Lai, T. L., &amp; Robbins, H. (1985). Asymptotically efficient adaptive allocation rules. <em class="EmphasisTypeItalic ">Advances in Applied Mathematics</em>, <em class="EmphasisTypeItalic ">6</em>(1), 4–22.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=776826"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1016/0196-8858(85)90002-8"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?0568.62074"><span><span>zbMATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Asymptotically%20efficient%20adaptive%20allocation%20rules&amp;author=TL.%20Lai&amp;author=H.%20Robbins&amp;journal=Advances%20in%20Applied%20Mathematics&amp;volume=6&amp;issue=1&amp;pages=4-22&amp;publication_year=1985"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR22">Ma, L. (1999). <em class="EmphasisTypeItalic ">Knowing and teaching elementary mathematics</em>. Mahwah, NJ: Lawrence Erlbaum Associates.<span class="Occurrences"><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?0938.00008"><span><span>zbMATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Knowing%20and%20teaching%20elementary%20mathematics&amp;author=L.%20Ma&amp;publication_year=1999"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR23">Malone, T. W., &amp; Bernstein, M. S. (2015). <em class="EmphasisTypeItalic ">Handbook of collective intelligence</em>. Massachusetts Institute of Technology. The MIT Press: Cambridge, MA.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Malone%2C%20T.%20W.%2C%20%26%20Bernstein%2C%20M.%20S.%20%282015%29.%20Handbook%20of%20collective%20intelligence.%20Massachusetts%20Institute%20of%20Technology.%20The%20MIT%20Press%3A%20Cambridge%2C%20MA."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR24">Manyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C., &amp; Byers, A. H. (2011). <em class="EmphasisTypeItalic ">Big data: the next frontier for innovation, competition, and productivity</em>. McKinsey Global Institute. Retrieved from &lt;<span class="ExternalRef"><a target="_blank" rel="noopener" href="http://www.mckinsey.com/insights/business_technology/big_data_the_next_frontier_for_innovation"><span class="RefSource">http://www.mckinsey.com/insights/business_technology/big_data_the_next_frontier_for_innovation</span></a></span>&gt;<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationContent" id="CR25">McAfee, A. P. (2006). Enterprise 2.0: the dawn of emergent collaboration. <em class="EmphasisTypeItalic ">MIT Sloan Management Review, 47</em>(3), 21–28.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=McAfee%2C%20A.%20P.%20%282006%29.%20Enterprise%202.0%3A%20the%20dawn%20of%20emergent%20collaboration.%C2%A0MIT%20Sloan%20Management%20Review%2C%2047%283%29%2C%2021%E2%80%9328."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR26">Mendicino, M., Razzaq, L. &amp; Heffernan, N. T. (2009). Improving Learning from Homework Using Intelligent Tutoring Systems. <em class="EmphasisTypeItalic ">Journal of Research on Technology in Education</em> (<em class="EmphasisTypeItalic ">JRTE</em>)<em class="EmphasisTypeItalic ">. 41</em>(3), 331–346.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Mendicino%2C%20M.%2C%20Razzaq%2C%20L.%20%26%20Heffernan%2C%20N.%20T.%20%282009%29.%20Improving%20Learning%20from%20Homework%20Using%20Intelligent%20Tutoring%20Systems.%20Journal%20of%20Research%20on%20Technology%20in%20Education%20%28JRTE%29.%2041%283%29%2C%20331%E2%80%93346."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR27">National Governors Association Center for Best Practices &amp; Council of Chief State School Officers. (2010). Common core state standards for mathematics. National governors association center for best practices, Council of Chief State School Officers, Washington D.C.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=National%20Governors%20Association%20Center%20for%20Best%20Practices%20%26%20Council%20of%20Chief%20State%20School%20Officers.%20%282010%29.%20Common%20core%20state%20standards%20for%20mathematics.%20National%20governors%20association%20center%20for%20best%20practices%2C%20Council%20of%20Chief%20State%20School%20Officers%2C%20Washington%20D.C."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR28">Organisciak, P., Teevan, J., Dumais, S., Miller, R. C., &amp; Kalai, A. T. (2014, May). A Crowd of Your Own: Crowdsourcing for On-Demand Personalization. In the <em class="EmphasisTypeItalic ">Second AAAI Conference on Human Computation and Crowdsourcing</em>.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Organisciak%2C%20P.%2C%20Teevan%2C%20J.%2C%20Dumais%2C%20S.%2C%20Miller%2C%20R.%20C.%2C%20%26%20Kalai%2C%20A.%20T.%20%282014%2C%20May%29.%20A%20Crowd%20of%20Your%20Own%3A%20Crowdsourcing%20for%20On-Demand%20Personalization.%20In%20the%20Second%20AAAI%20Conference%20on%20Human%20Computation%20and%20Crowdsourcing."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR29">Ostrow, K. S. &amp; Heffernan, N. T. (2014). Testing the Multimedia Principle in the Real World: A Comparison of Video vs. Text Feedback in Authentic Middle School Math Assignments. In Stamper, J., Pardos, Z., Mavrikis, M., McLaren, B.M. (eds.) <em class="EmphasisTypeItalic ">Proceedings of the 7th International Conference on Educational Data Mining</em>. pp. 296–299.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Ostrow%2C%20K.%20S.%20%26%20Heffernan%2C%20N.%20T.%20%282014%29.%20Testing%20the%20Multimedia%20Principle%20in%20the%20Real%20World%3A%20A%20Comparison%20of%20Video%20vs.%20Text%20Feedback%20in%20Authentic%20Middle%20School%20Math%20Assignments.%20In%20Stamper%2C%20J.%2C%20Pardos%2C%20Z.%2C%20Mavrikis%2C%20M.%2C%20McLaren%2C%20B.M.%20%28eds.%29%20Proceedings%20of%20the%207th%20International%20Conference%20on%20Educational%20Data%20Mining.%20pp.%20296%E2%80%93299."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR30">Porcello, D., &amp; Hsi, S. (2013). Crowdsourcing and curating online education resources. <em class="EmphasisTypeItalic ">Science</em>, <em class="EmphasisTypeItalic ">341</em>(6143), 240–241.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1126/science.1234722"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Crowdsourcing%20and%20curating%20online%20education%20resources&amp;author=D.%20Porcello&amp;author=S.%20Hsi&amp;journal=Science&amp;volume=341&amp;issue=6143&amp;pages=240-241&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR31">Retelny, D., Robaszkiewicz, S., To, A., Lasecki, W. S., Patel, J., Rahmati, N.,... &amp; Bernstein, M. S. (2014, October). Expert crowdsourcing with flash teams. In <em class="EmphasisTypeItalic ">Proceedings of the 27th annual ACM symposium on User interface software and technology</em>. pp. 75–85. ACM.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Retelny%2C%20D.%2C%20Robaszkiewicz%2C%20S.%2C%20To%2C%20A.%2C%20Lasecki%2C%20W.%20S.%2C%20Patel%2C%20J.%2C%20Rahmati%2C%20N.%2C...%20%26%20Bernstein%2C%20M.%20S.%20%282014%2C%20October%29.%20Expert%20crowdsourcing%20with%20flash%20teams.%20In%20Proceedings%20of%20the%2027th%20annual%20ACM%20symposium%20on%20User%20interface%20software%20and%20technology.%20pp.%2075%E2%80%9385.%20ACM."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR32">Robbins, H. (1952). Some aspects of the sequential design of experiments. In <em class="EmphasisTypeItalic ">Herbert Robbins Selected Papers</em> (pp. 169–177). New York: Springer.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Some%20aspects%20of%20the%20sequential%20design%20of%20experiments&amp;author=H.%20Robbins&amp;pages=169-177&amp;publication_year=1952"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR33">Saxton, G. D., Oh, O., &amp; Kishore, R. (2013). Rules of crowdsourcing: models, issues, and systems of control. <em class="EmphasisTypeItalic ">Information Systems Management.</em>, <em class="EmphasisTypeItalic ">30</em>(1), 2–20.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1080/10580530.2013.739883"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Rules%20of%20crowdsourcing%3A%20models%2C%20issues%2C%20and%20systems%20of%20control&amp;author=GD.%20Saxton&amp;author=O.%20Oh&amp;author=R.%20Kishore&amp;journal=Information%20Systems%20Management.&amp;volume=30&amp;issue=1&amp;pages=2-20&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR34">Schwartz, D. L., &amp; Bransford, J. D. (1998). A time for telling. <em class="EmphasisTypeItalic ">Cognition and Instruction</em>, <em class="EmphasisTypeItalic ">16</em>(4), 475–5223.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1207/s1532690xci1604_4"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=A%20time%20for%20telling&amp;author=DL.%20Schwartz&amp;author=JD.%20Bransford&amp;journal=Cognition%20and%20Instruction&amp;volume=16&amp;issue=4&amp;pages=475-5223&amp;publication_year=1998"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR35">Selent, D. &amp; Heffernan, N. T. (2015) When More Intelligent Tutoring in the Form of Buggy Messages Does Not Help. In Conati, Heffernan, Mitrovic &amp; Verdejo (eds) <em class="EmphasisTypeItalic ">The 17th Proceedings of the Conference on Artificial Intelligence in Education</em> (<em class="EmphasisTypeItalic ">AIED 2015</em>). Springer. pp. 768–771.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Selent%2C%20D.%20%26%20Heffernan%2C%20N.%20T.%20%282015%29%20When%20More%20Intelligent%20Tutoring%20in%20the%20Form%20of%20Buggy%20Messages%20Does%20Not%20Help.%20In%20Conati%2C%20Heffernan%2C%20Mitrovic%20%26%20Verdejo%20%28eds%29%20The%2017th%20Proceedings%20of%20the%20Conference%20on%20Artificial%20Intelligence%20in%20Education%20%28AIED%202015%29.%20Springer.%20pp.%20768%E2%80%93771."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR36">Surowiecki, J. (2004). <em class="EmphasisTypeItalic ">The wisdom of crowds</em>. New York: Doubleday.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Surowiecki%2C%20J.%20%282004%29.%20The%20wisdom%20of%20crowds.%20New%20York%3A%20Doubleday."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR37">Tan, W., Blake, M. B., Saleh, I., &amp; Dustdar, S. (2013). Social-network-sourced big data analytics. <em class="EmphasisTypeItalic ">IEEE Internet Computing</em>, <em class="EmphasisTypeItalic ">5</em>, 62–69.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1109/MIC.2013.100"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Social-network-sourced%20big%20data%20analytics&amp;author=W.%20Tan&amp;author=MB.%20Blake&amp;author=I.%20Saleh&amp;author=S.%20Dustdar&amp;journal=IEEE%20Internet%20Computing&amp;volume=5&amp;pages=62-69&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR38">Van der Kleij, F.M., Feskens, R.C.W., &amp; Eggen, T.J.H.M. (2015). Effects of Feedback in a Computer-Based Learning Environment on Students’ Learning Outcomes: A Meta-Analysis. <em class="EmphasisTypeItalic ">Review of Educational Research</em>, AERA. 85 (4). pp. 475–511.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Van%20der%20Kleij%2C%20F.M.%2C%20Feskens%2C%20R.C.W.%2C%20%26%20Eggen%2C%20T.J.H.M.%20%282015%29.%20Effects%20of%20Feedback%20in%20a%20Computer-Based%20Learning%20Environment%20on%20Students%E2%80%99%20Learning%20Outcomes%3A%20A%20Meta-Analysis.%20Review%20of%20Educational%20Research%2C%20AERA.%2085%20%284%29.%20pp.%20475%E2%80%93511."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR39">Van Inwegen, E., Wang, Y., Adjei, S. &amp; Heffernan, N.T. (2015) The Effect of the Distribution of Predictions of User Models. In Santos, Boticario, Romero, Pechenizkiy, Merceron, Mitros, Luna, Mihaescu, Moreno, Hershkovitz, Ventura, &amp; Desmarais (eds.) <em class="EmphasisTypeItalic ">Proceedings of the 8th International Conference on Educational Data Mining</em> (<em class="EmphasisTypeItalic ">EDM 2015</em>)<em class="EmphasisTypeItalic ">.</em>
                        <span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Van%20Inwegen%2C%20E.%2C%20Wang%2C%20Y.%2C%20Adjei%2C%20S.%20%26%20Heffernan%2C%20N.T.%20%282015%29%20The%20Effect%20of%20the%20Distribution%20of%20Predictions%20of%20User%20Models.%20In%20Santos%2C%20Boticario%2C%20Romero%2C%20Pechenizkiy%2C%20Merceron%2C%20Mitros%2C%20Luna%2C%20Mihaescu%2C%20Moreno%2C%20Hershkovitz%2C%20Ventura%2C%20%26%20Desmarais%20%28eds.%29%20Proceedings%20of%20the%208th%20International%20Conference%20on%20Educational%20Data%20Mining%20%28EDM%202015%29.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR40">Von Ahn, L., &amp; Dabbish, L. (2008). Designing games with a purpose. <em class="EmphasisTypeItalic ">Communications of the ACM</em>, <em class="EmphasisTypeItalic ">51</em>(8), 58–67.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Designing%20games%20with%20a%20purpose&amp;author=L.%20Ahn&amp;author=L.%20Dabbish&amp;journal=Communications%20of%20the%20ACM&amp;volume=51&amp;issue=8&amp;pages=58-67&amp;publication_year=2008"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR41">Von Ahn, L. (2009, July). Human computation. In <em class="EmphasisTypeItalic ">Design Automation Conference</em>, <em class="EmphasisTypeItalic ">2009. DAC</em>’<em class="EmphasisTypeItalic ">09. 46th ACM</em>/<em class="EmphasisTypeItalic ">IEEE</em> pp. 418–419. IEEE.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Von%20Ahn%2C%20L.%20%282009%2C%20July%29.%20Human%20computation.%20In%20Design%20Automation%20Conference%2C%202009.%20DAC%E2%80%9909.%2046th%20ACM%2FIEEE%20pp.%20418%E2%80%93419.%20IEEE."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR42">Wegscheider, K. (1998). Advantages and disadvantages of sequential designs. <em class="EmphasisTypeItalic ">Herzschrittmachertherapie und Elektrophysiologie</em>, <em class="EmphasisTypeItalic ">9</em>(4), 248–254.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1007/s003990050035"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Advantages%20and%20disadvantages%20of%20sequential%20designs&amp;author=K.%20Wegscheider&amp;journal=Herzschrittmachertherapie%20und%20Elektrophysiologie&amp;volume=9&amp;issue=4&amp;pages=248-254&amp;publication_year=1998"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR43">Weir, S., Kim, J., Gajos, K., &amp; Miller, R. (2015). Learnersourcing subgoal labels for how-to videos, <em class="EmphasisTypeItalic ">proceedings of the 18th ACM conference on computer supported cooperative work</em> &amp; <em class="EmphasisTypeItalic ">social computing</em>.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Weir%2C%20S.%2C%20Kim%2C%20J.%2C%20Gajos%2C%20K.%2C%20%26%20Miller%2C%20R.%20%282015%29.%20Learnersourcing%20subgoal%20labels%20for%20how-to%20videos%2C%20proceedings%20of%20the%2018th%20ACM%20conference%20on%20computer%20supported%20cooperative%20work%20%26%20social%20computing."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR44">Weld, D., Adar, E., Chilton, L., Hoffmann, R., Horvitz, E., Koch, M., Landay, J., Lin, C. H., &amp; Mausam. (2012). Personalized online education- a crowdsourcing challenge. AAAI Workshops, North America. Retrieved from &lt;<span class="ExternalRef"><a target="_blank" rel="noopener" href="https://www.aaai.org/ocs/index.php/WS/AAAIW12/paper/view/5306/5620"><span class="RefSource">https://www.aaai.org/ocs/index.php/WS/AAAIW12/paper/view/5306/5620</span></a></span>&gt;<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationContent" id="CR45">Williams, J., J., Li, N., Kim, J., Whitehill, J., Maldonado, S., Pechenizkiy, M., Chu, L., &amp; Heffernan, N. (2014). MOOClets: a framework for improving online education through experimental comparison and personalization of modules (working paper no. 2523265)<em class="EmphasisTypeItalic ">.</em> Retrieved from the Social Science Research Network: <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://ssrn.com/abstract=2523265"><span class="RefSource">http://ssrn.com/abstract=2523265</span></a></span>
                        <span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationContent" id="CR46">Williams, J. J., &amp; Lombrozo, T. (2010). The role of explanation in discovery and generalization: evidence from category learning. <em class="EmphasisTypeItalic ">Cognitive Science</em>, <em class="EmphasisTypeItalic ">34</em>, 776–806.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1111/j.1551-6709.2010.01113.x"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=The%20role%20of%20explanation%20in%20discovery%20and%20generalization%3A%20evidence%20from%20category%20learning&amp;author=JJ.%20Williams&amp;author=T.%20Lombrozo&amp;journal=Cognitive%20Science&amp;volume=34&amp;pages=776-806&amp;publication_year=2010"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR47">Williams, J. J., Krause, M., Paritosh, P., Whitehill, J., Reich, J., Kim, J., et al. (2015a). Connecting collaborative &amp; crowd work with online education. In <em class="EmphasisTypeItalic ">Proceedings of the 18th ACM Conference Companion on Computer Supported Cooperative Work &amp; Social Computing</em> (pp. 313–318). ACM.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Williams%2C%20J.%20J.%2C%20Krause%2C%20M.%2C%20Paritosh%2C%20P.%2C%20Whitehill%2C%20J.%2C%20Reich%2C%20J.%2C%20Kim%2C%20J.%2C%20et%20al.%20%282015a%29.%20Connecting%20collaborative%20%26%20crowd%20work%20with%20online%20education.%20In%20Proceedings%20of%20the%2018th%20ACM%20Conference%20Companion%20on%20Computer%20Supported%20Cooperative%20Work%C2%A0%26%20Social%20Computing%20%28pp.%20313%E2%80%93318%29.%20ACM."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR48">Williams, J. J., Ostrow, K., Xiong, X., Glassman, E., Kim, J., Maldonado, S. G., et al. (2015b). Using and designing platforms for in vivo educational experiments. In D. M. Russell, B. Woolf &amp; G. Kiczales (Eds), <em class="EmphasisTypeItalic ">Proceedings of the 2nd ACM Conference on Learning at Scale</em>, pp. 409–412.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Williams%2C%20J.%20J.%2C%20Ostrow%2C%20K.%2C%20Xiong%2C%20X.%2C%20Glassman%2C%20E.%2C%20Kim%2C%20J.%2C%20Maldonado%2C%20S.%20G.%2C%20et%20al.%20%282015b%29.%C2%A0Using%20and%20designing%20platforms%20for%20in%20vivo%20educational%20experiments.%20In%20D.%20M.%20Russell%2C%20B.%20Woolf%20%26%20G.%20Kiczales%20%28Eds%29%2C%C2%A0Proceedings%20of%20the%202nd%20ACM%20Conference%20on%20Learning%20at%20Scale%2C%20pp.%20409%E2%80%93412."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationContent" id="CR49">Zhang, J., Kong, X., Luo, R.J., Chang, Y., &amp; Yu, P.S. (2014). NCR: A Scalable Network-Based Approach to Co-Ranking in Question-and-Answer Sites. <em class="EmphasisTypeItalic ">Proceedings of the 23rd ACM International Conference on Information and Knowledge Management</em>. pp 709–718.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Zhang%2C%20J.%2C%20Kong%2C%20X.%2C%20Luo%2C%20R.J.%2C%20Chang%2C%20Y.%2C%20%26%20Yu%2C%20P.S.%20%282014%29.%20NCR%3A%20A%20Scalable%20Network-Based%20Approach%20to%20Co-Ranking%20in%20Question-and-Answer%20Sites.%20Proceedings%20of%20the%2023rd%20ACM%20International%20Conference%20on%20Information%20and%20Knowledge%20Management.%20pp%20709%E2%80%93718."><span><span>Google Scholar</span></span></a></span></span></div></li></ol></div></section><section class="Section1 RenderAsSection1"><h2 class="Heading" id="copyrightInformation">Copyright information</h2><div class="ArticleCopyright content"><div class="ArticleCopyright">© International Artificial Intelligence in Education Society 2016</div></div></section><section id="authorsandaffiliations" class="Section1 RenderAsSection1"><h2 class="Heading">Authors and Affiliations</h2><div class="content authors-affiliations u-interface"><ul class="test-contributor-names"><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Neil T. Heffernan</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Korinn S. Ostrow</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul><span class="author-information"><span class="author-information__contact u-icon-before"><a href="mailto:ksostrow@wpi.edu" title="ksostrow@wpi.edu" itemprop="email" data-track="click" data-track-action="Email author" data-track-label="">Email author</a></span></span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Kim Kelly</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Douglas Selent</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Eric G. Van Inwegen</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Xiaolu Xiong</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Joseph Jay Williams</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-2">2</li></ul></li></ul><ol class="test-affiliations"><li class="affiliation" data-test="affiliation-1" data-affiliation-highlight="affiliation-1" itemscope="" itemtype="http://schema.org/Organization"><span class="affiliation__count">1.</span><span class="affiliation__item"><span itemprop="name" class="affiliation__name">Worcester Polytechnic Institute</span><span itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress" class="affiliation__address"><span itemprop="addressRegion" class="affiliation__city">Worcester</span><span itemprop="addressCountry" class="affiliation__country">USA</span></span></span></li><li class="affiliation" data-test="affiliation-2" data-affiliation-highlight="affiliation-2" itemscope="" itemtype="http://schema.org/Organization"><span class="affiliation__count">2.</span><span class="affiliation__item"><span itemprop="department" class="affiliation__department">HarvardX</span><span itemprop="name" class="affiliation__name">Harvard University</span><span itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress" class="affiliation__address"><span itemprop="addressRegion" class="affiliation__city">Cambridge</span><span itemprop="addressCountry" class="affiliation__country">USA</span></span></span></li></ol></div></section></div>
                        </article>
                        <aside class="section section--collapsible" id="AboutThisContent">
    <h2 class="section__heading" id="aboutcontent">About this article</h2>
    <div class="section__content bibliographic-information">
                <div id="crossMark" class="crossmark">
            <a data-crossmark="10.1007%2Fs40593-016-0094-z" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007%2Fs40593-016-0094-z" title="Verify currency and authenticity via CrossMark" data-track="click" data-track-action="Crossmark" data-track-label="">
                <span class="u-screenreader-only">CrossMark</span>
                <svg class="CrossMark" id="crossmark-icon" width="57" height="81">
                    <image width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="/springerlink-static/2055516157/images/png/crossmark.png" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="/springerlink-static/2055516157/images/svg/crossmark.svg"></image>
                </svg>
            </a>
        </div>

        <div class="crossmark__adjacent">
            <dl class="citation-info u-highlight-target u-mb-16" id="citeas" tabindex="-1">
    <dt class="test-cite-heading">
        Cite this article as:
    </dt>
    <dd id="citethis-text">Heffernan, N.T., Ostrow, K.S., Kelly, K. et al. Int J Artif Intell Educ (2016) 26: 615. https://doi.org/10.1007/s40593-016-0094-z</dd>
</dl>
                <ul class="bibliographic-information__list bibliographic-information__list--inline">
        <li class="bibliographic-information__item">
            <span class="bibliographic-information__title">First Online</span>
            <span class="bibliographic-information__value u-overflow-wrap">02 February 2016</span>
        </li>
        <li class="bibliographic-information__item">
            <span class="bibliographic-information__title">DOI</span>
            <span class="bibliographic-information__value u-overflow-wrap" id="doi-url">https://doi.org/10.1007/s40593-016-0094-z</span>
        </li>
            <li class="bibliographic-information__item">
                <span class="bibliographic-information__title">Publisher Name</span>
                <span class="bibliographic-information__value" id="publisher-name">Springer New York</span>
            </li>
            <li class="bibliographic-information__item">
                <span class="bibliographic-information__title">Print ISSN</span>
                <span class="bibliographic-information__value" id="print-issn">1560-4292</span>
            </li>
            <li class="bibliographic-information__item">
                <span class="bibliographic-information__title">Online ISSN</span>
                <span class="bibliographic-information__value" id="electronic-issn">1560-4306</span>
            </li>

        
    </ul>

            <ul class="bibliographic-information__list">
        <li class="bibliographic-information__item">
            <a id="about-journal" class="bibliographic-information__misc-links"
               title="Visit Springer.com for information about this article&#39;s journal"
               href="//www.springer.com/journal/40593/about">About this journal</a>
        </li>
        <li class="bibliographic-information__item">
            <a id="reprintsandpermissions-link" target="_blank" rel="noopener" href="https://s100.copyright.com/AppDispatchServlet?publisherName&#x3D;SpringerNature&amp;orderBeanReset&#x3D;true&amp;orderSource&#x3D;SpringerLink&amp;copyright&#x3D;International+Artificial+Intelligence+in+Education+Society&amp;author&#x3D;Neil+T.+Heffernan%2C+Korinn+S.+Ostrow%2C+Kim+Kelly+et+al&amp;issueNum&#x3D;2&amp;contentID&#x3D;10.1007%2Fs40593-016-0094-z&amp;endPage&#x3D;644&amp;publicationDate&#x3D;2016&amp;startPage&#x3D;615&amp;volumeNum&#x3D;26&amp;title&#x3D;The+Future+of+Adaptive+Learning%3A+Does+the+Crowd+Hold+the+Key%3F&amp;imprint&#x3D;International+Artificial+Intelligence+in+Education+Society&amp;publication&#x3D;1560-4292" title="Visit RightsLink for information about reusing this article" data-track="click" data-track-action="Reprints and Permissions" data-track-label="">Reprints and Permissions</a>
        </li>
</ul>



        </div>
      
      
          <div class="partner-public"><ul>
<li>
  <div class="partner-logos__logo">
    <img style="display:block"
      src="//published-with.public.springernature.app/aied.jpg"
      alt="aied">
  </div>
  <div class="partner-logos__caption">
    <p>Published in cooperation with</p>
    <a class="external" href="http://ijaied.org/about/"
      title="Visit this website" target="_blank"
      rel="noopener noreferrer" data-track="click" data-track-action="Co-publisher" data-track-label="">aied</a>
  </div>
</li>
    
</ul></div>
    </div>
</aside>

                        <div class="section section--collapsible uptodate-recommendations gtm-recommendations">
    <h2 class="uptodate-recommendations__title section__heading gtm-recommendations__title" id="uptodaterecommendations">Personalised recommendations</h2>
    <div class="section__content">
        <div class="uptodate-recommendations__container">
             <link rel="uptodate-inline" href="/springerlink-static/2055516157/css/recommendations.css"/>
        </div>
    </div>
</div>
                                <div id="doubleclick-native-ad" data-component="SpringerLink.GoogleAds" data-namespace="native"></div>

                                    <div class="sticky-banner 
            u-interface u-js-screenreader-only" aria-hidden="true" data-component="SpringerLink.StickyBanner" data-namespace="hasButton">
                <div class="sticky-banner__container">
                        <div class="citations" data-component="SV.Dropdown" data-namespace="citationsSticky">
        <h3 class="u-h4" data-role="button-dropdown__title">
    <span>Cite</span>
    <span class="hide-text-small">article</span>
</h3>
<ul class="citations__content" data-role="button-dropdown__content">
    <li>
        <a href="#citeas" data-track="click" data-track-action="Cite as link" data-track-label="Cite dropdown">How to cite?</a>
    </li>
        <li>
            <a href="//citation-needed.springer.com/v2/references/10.1007/s40593-016-0094-z?format&#x3D;refman&amp;flavour&#x3D;citation"
               title="Download this article&#39;s citation as a .RIS file" data-track="click" data-track-action="Export citation" data-track-label="RIS">
                <span class="citations__extension" data-gtmlabel="RIS">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#004aa7"/></svg>
                    .RIS
                </span>
                <span class="citations__types">
                        <span>
                            Papers
                        </span>
                        <span>
                            Reference Manager
                        </span>
                        <span>
                            RefWorks
                        </span>
                        <span>
                            Zotero
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="//citation-needed.springer.com/v2/references/10.1007/s40593-016-0094-z?format&#x3D;endnote&amp;flavour&#x3D;citation"
               title="Download this article&#39;s citation as a .ENW file" data-track="click" data-track-action="Export citation" data-track-label="ENW">
                <span class="citations__extension" data-gtmlabel="ENW">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#004aa7"/></svg>
                    .ENW
                </span>
                <span class="citations__types">
                        <span>
                            EndNote
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="//citation-needed.springer.com/v2/references/10.1007/s40593-016-0094-z?format&#x3D;bibtex&amp;flavour&#x3D;citation"
               title="Download this article&#39;s citation as a .BIB file" data-track="click" data-track-action="Export citation" data-track-label="BIB">
                <span class="citations__extension" data-gtmlabel="BIB">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#004aa7"/></svg>
                    .BIB
                </span>
                <span class="citations__types">
                        <span>
                            BibTeX
                        </span>
                        <span>
                            JabRef
                        </span>
                        <span>
                            Mendeley
                        </span>
                </span>
            </a>
        </li>
</ul>
    </div>

                            <div>
        <a class="c-button share-this test-shareby-sharelink-link" data-test="shareable-link" target="_blank" rel="noopener" href="/sharelink/10.1007/s40593-016-0094-z" data-track="click" data-track-action="Share via" data-track-label="ShareLink">
            <span>Share</span>
            <span class="hide-text-small">article</span>
        </a>
    </div>




                                    <div>
            <a href="/content/pdf/10.1007%2Fs40593-016-0094-z.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right" title="Download this article in PDF format" rel="noopener" data-track="click" data-track-action="Pdf download" data-track-label="">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"/></g></g></g></svg>
                <span class="hide-text-small">Download</span>
                <span>PDF</span>
            </a>
        </div>

                </div>
            </div>




                    </div>
                    <aside class="main-sidebar-right u-interface">
                        <div data-role="sticky-wrapper">
                            <div class="main-sidebar-right__content u-composite-layer" data-component="SpringerLink.StickySidebar">
                                <div class="article-actions" id="article-actions">
                                    <h2 class="u-screenreader-only" aria-hidden="true">Actions</h2>


                                    <div class="u-js-hide u-js-show-two-col">
                                        

                                                <div class="download-article test-pdf-link">
                                                            <div>
            <a href="/content/pdf/10.1007%2Fs40593-016-0094-z.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right" title="Download this article in PDF format" rel="noopener" data-track="click" data-track-action="Pdf download" data-track-label="">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"/></g></g></g></svg>
                <span class="hide-text-small">Download</span>
                <span>PDF</span>
            </a>
        </div>

                                                </div>


                                            <div class="citations" data-component="SV.Dropdown" data-namespace="citations">
        <h3 class="u-h4" data-role="button-dropdown__title">
    <span>Cite</span>
    <span class="hide-text-small">article</span>
</h3>
<ul class="citations__content" data-role="button-dropdown__content">
    <li>
        <a href="#citeas" data-track="click" data-track-action="Cite as link" data-track-label="Cite dropdown">How to cite?</a>
    </li>
        <li>
            <a href="//citation-needed.springer.com/v2/references/10.1007/s40593-016-0094-z?format&#x3D;refman&amp;flavour&#x3D;citation"
               title="Download this article&#39;s citation as a .RIS file" data-track="click" data-track-action="Export citation" data-track-label="RIS">
                <span class="citations__extension" data-gtmlabel="RIS">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#004aa7"/></svg>
                    .RIS
                </span>
                <span class="citations__types">
                        <span>
                            Papers
                        </span>
                        <span>
                            Reference Manager
                        </span>
                        <span>
                            RefWorks
                        </span>
                        <span>
                            Zotero
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="//citation-needed.springer.com/v2/references/10.1007/s40593-016-0094-z?format&#x3D;endnote&amp;flavour&#x3D;citation"
               title="Download this article&#39;s citation as a .ENW file" data-track="click" data-track-action="Export citation" data-track-label="ENW">
                <span class="citations__extension" data-gtmlabel="ENW">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#004aa7"/></svg>
                    .ENW
                </span>
                <span class="citations__types">
                        <span>
                            EndNote
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="//citation-needed.springer.com/v2/references/10.1007/s40593-016-0094-z?format&#x3D;bibtex&amp;flavour&#x3D;citation"
               title="Download this article&#39;s citation as a .BIB file" data-track="click" data-track-action="Export citation" data-track-label="BIB">
                <span class="citations__extension" data-gtmlabel="BIB">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#004aa7"/></svg>
                    .BIB
                </span>
                <span class="citations__types">
                        <span>
                            BibTeX
                        </span>
                        <span>
                            JabRef
                        </span>
                        <span>
                            Mendeley
                        </span>
                </span>
            </a>
        </li>
</ul>
    </div>

                                                <div>
        <a class="c-button share-this test-shareby-sharelink-link" data-test="shareable-link" target="_blank" rel="noopener" href="/sharelink/10.1007/s40593-016-0094-z" data-track="click" data-track-action="Share via" data-track-label="ShareLink">
            <span>Share</span>
            <span class="hide-text-small">article</span>
        </a>
    </div>




                                    </div>
                                </div>
                                <nav class="toc" aria-label="article contents">
    <h2 class="u-screenreader-only" aria-hidden="true">Table of contents</h2>
    <ul id="article-contents" class="article-contents" tabindex="-1">
            <li>
                <a title="Article" href="#enumeration"><span class="u-overflow-ellipsis">Article</span></a>
            </li>
            <li>
                <a title="Abstract" href="#Abs1"><span class="u-overflow-ellipsis">Abstract</span></a>
            </li>
            <li>
                <a title="Evolving Adaptive Learning Technologies Through Crowdsourced Contributions" href="#Sec1"><span class="u-overflow-ellipsis">Evolving Adaptive Learning Technologies Through Crowdsourced Contributions</span></a>
            </li>
            <li>
                <a title="Crowdsourcing" href="#Sec2"><span class="u-overflow-ellipsis">Crowdsourcing</span></a>
            </li>
            <li>
                <a title="Implementing Crowdsourcing Within Assistments" href="#Sec6"><span class="u-overflow-ellipsis">Implementing Crowdsourcing Within Assistments</span></a>
            </li>
            <li>
                <a title="Evaluating Crowdsourced Content via Randomized Controlled Experiments" href="#Sec10"><span class="u-overflow-ellipsis">Evaluating Crowdsourced Content via Randomized Controlled Experiments</span></a>
            </li>
            <li>
                <a title="Motivating Participation in Learnersourcing" href="#Sec15"><span class="u-overflow-ellipsis">Motivating Participation in Learnersourcing</span></a>
            </li>
            <li>
                <a title="IMPLEMENTING LEARNERSOURCED FEEDBACK WITHIN ASSISTMENTS: PEERASSIST" href="#Sec16"><span class="u-overflow-ellipsis">IMPLEMENTING LEARNERSOURCED FEEDBACK WITHIN ASSISTMENTS: PEERASSIST</span></a>
            </li>
            <li>
                <a title="Lessons Learned and a Call to the Community" href="#Sec18"><span class="u-overflow-ellipsis">Lessons Learned and a Call to the Community</span></a>
            </li>
            <li>
                <a title="Closing Thoughts" href="#Sec19"><span class="u-overflow-ellipsis">Closing Thoughts</span></a>
            </li>
            <li>
                <a title="Notes" href="#Notes"><span class="u-overflow-ellipsis">Notes</span></a>
            </li>
            <li>
                <a title="References" href="#Bib1"><span class="u-overflow-ellipsis">References</span></a>
            </li>
            <li>
                <a title="Copyright information" href="#copyrightInformation"><span class="u-overflow-ellipsis">Copyright information</span></a>
            </li>
            <li>
                <a title="Authors and Affiliations" href="#authorsandaffiliations"><span class="u-overflow-ellipsis">Authors and Affiliations</span></a>
            </li>
            <li>
                <a title="About this article" href="#aboutcontent"><span class="u-overflow-ellipsis">About this article</span></a>
            </li>
    </ul>
</nav>

                            </div>
                                <div class="skyscraper-ad u-hide" data-component="SpringerLink.GoogleAds" data-namespace="skyscraper">
        <div class="skyscraper-ad__wrapper">
            <p class="skyscraper-ad__label">Advertisement</p>
            <button class="skyscraper-ad__hide" title="Hide this advertisement" data-track="click" data-track-action="Hide advertisement" data-track-label="">Hide</button>
            <div id="doubleclick-ad" class="skyscraper-ad__ad"></div>
        </div>
    </div>

                        </div>
                    </aside>
                </div>
            </main>
                <footer class="footer u-interface">
        <div class="footer__aside-wrapper">
            <div class="footer__content">
                <div class="footer__aside">
                    <p class="footer__strapline">Over 10 million scientific documents at your fingertips</p>
                                <div class="footer__edition" data-component="SV.EditionSwitcher">
                                    <h3 class="u-hide" data-role="button-dropdown__title" data-btn-text="Switch between Academic &#38; Corporate Edition">Switch Edition</h3>
                                    <ul data-role="button-dropdown__content">
                                        <li  class="selected"><a href="/siteEdition/link?previousUrl=/article/10.1007/s40593-016-0094-z&id=siteedition-academic-link" id="siteedition-academic-link">Academic Edition</a></li>
                                        <li ><a href="/siteEdition/rd?previousUrl=/article/10.1007/s40593-016-0094-z&id=siteedition-corporate-link" id="siteedition-corporate-link">Corporate Edition</a></li>
                                    </ul>
                                </div>
                </div>
            </div>
        </div>
        <div class="footer__content">
            <ul class="footer__nav">
                <li>
                    <a href="/">Home</a>
                </li>
                <li>
                    <a href="/impressum">Impressum</a>
                </li>
                <li>
                    <a href="/termsandconditions">Legal information</a>
                </li>
                <li>
                    <a href="/privacystatement">Privacy statement</a>
                </li>
                <li>
                    <a href="/cookiepolicy">How we use cookies</a>
                </li>
                <li>
                    <a href="/accessibility">Accessibility</a>
                </li>
                <li>
                    <a id="contactus-footer-link" href="/contactus">Contact us</a>
                </li>
            </ul>
            <a class="parent-logo"
               target="_blank" rel="noopener"
               href="//www.springernature.com"
               title="Go to Springer Nature">
                <span class="u-screenreader-only">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12"
                           src="/springerlink-static/2055516157/images/png/springernature.png"
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href="/springerlink-static/2055516157/images/svg/springernature.svg">
                    </image>
                </svg>
            </a>

            <p class="footer__copyright">&copy; 2018 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
                <p class="footer__user-access-info">
                    <span>Not logged in</span>
                    <span>Not affiliated</span>
                    <span>24.1.89.72</span>
                </p>
        </div>
    </footer>

        </div>
        <script type="text/javascript">
    (function() {
        var linkEl = document.querySelector('.js-ctm');
        var scriptsList = [];
        var polyfillFeatures = '';

        window.SpringerLink = window.SpringerLink || {};
        window.SpringerLink.staticLocation = '/springerlink-static/2055516157';
        window.eventTrackerInstance = null;

        if (window.matchMedia && window.matchMedia(linkEl.media).matches) {
            (function(h){h.className = h.className.replace('no-js', 'js')})(document.documentElement);

            polyfillFeatures = 'default,fetch,Promise,Object.setPrototypeOf,Object.entries,Number.isInteger,MutationObserver,startsWith,Array.prototype.includes,Array.from,IntersectionObserver';

            scriptsList = [
                'https://cdn.polyfill.io/v2/polyfill.min.js?features=' + polyfillFeatures + '&flags=gated',
                window.SpringerLink.staticLocation + '/js/main.js'
            ];

            scriptsList.forEach(function(script) {
                var tag = document.createElement('script');
                tag.async = false;
                tag.src = script;

                document.body.appendChild(tag);
            });
        }
    })();
</script>



    <script type="text/javascript" id="googletag-push">
        
            var adSlot = '270604982/springerlink/40593/article';
        

        var definedSlots = [
                {slot: [728, 90], containerName: 'doubleclick-leaderboard-ad'},
                {slot: [160, 600], containerName: 'doubleclick-ad'},
            {slot: [2, 2], containerName: 'doubleclick-native-ad'}
        ];
    </script>


        
        <span id="chat-widget" class="u-hide"></span>
                    <noscript>
                <img aria-hidden="true" role="presentation" src="https://ssl-springer.met.vgwort.de/na/vgzm.415900-10.1007-s40593-016-0094-z" width='1' height='1' alt='' />
            </noscript>

    </body>
</html>
